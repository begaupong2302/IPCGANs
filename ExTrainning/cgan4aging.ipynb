{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f877817b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-02T16:40:02.437842Z",
     "iopub.status.busy": "2025-01-02T16:40:02.437522Z",
     "iopub.status.idle": "2025-01-02T16:40:06.783326Z",
     "shell.execute_reply": "2025-01-02T16:40:06.782290Z"
    },
    "papermill": {
     "duration": 4.352171,
     "end_time": "2025-01-02T16:40:06.785062",
     "exception": false,
     "start_time": "2025-01-02T16:40:02.432891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b988987",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T16:40:06.792274Z",
     "iopub.status.busy": "2025-01-02T16:40:06.791857Z",
     "iopub.status.idle": "2025-01-02T16:40:06.797991Z",
     "shell.execute_reply": "2025-01-02T16:40:06.797042Z"
    },
    "papermill": {
     "duration": 0.01103,
     "end_time": "2025-01-02T16:40:06.799415",
     "exception": false,
     "start_time": "2025-01-02T16:40:06.788385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def check_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "class Img_to_zero_center(object):\n",
    "    def __int__(self):\n",
    "        pass\n",
    "    def __call__(self, t_img):\n",
    "        '''\n",
    "        :param img:tensor be 0-1\n",
    "        :return:\n",
    "        '''\n",
    "        t_img=(t_img-0.5)*2\n",
    "        return t_img\n",
    "\n",
    "class Reverse_zero_center(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self,t_img):\n",
    "        t_img=t_img/2+0.5\n",
    "        return t_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da663b78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T16:40:06.805784Z",
     "iopub.status.busy": "2025-01-02T16:40:06.805502Z",
     "iopub.status.idle": "2025-01-02T16:40:07.947429Z",
     "shell.execute_reply": "2025-01-02T16:40:07.946277Z"
    },
    "papermill": {
     "duration": 1.147013,
     "end_time": "2025-01-02T16:40:07.949117",
     "exception": false,
     "start_time": "2025-01-02T16:40:06.802104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 3, 1, 1, 4, 0, 4, 0, 4, 2, 4, 2, 4, 1, 4, 2, 0, 1, 4, 3, 0, 3, 4,\n",
      "        2, 1, 0, 1, 0, 0, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets.folder import pil_loader\n",
    "from random import shuffle\n",
    "\n",
    "class CACD(data.Dataset):\n",
    "    def __init__(self,split=\"train\",transforms=None, label_transforms=None):\n",
    "\n",
    "        self.split=split\n",
    "\n",
    "        #define label 128*128 for condition generate image\n",
    "        list_root = \"/kaggle/input/utkpreprocess/lists\"\n",
    "        data_root = \"/kaggle/input/utkpreprocess/UTKFaceCrop\"\n",
    "\n",
    "        self.condition128=[]\n",
    "        full_one=np.ones((128,128),dtype=np.float32)\n",
    "        for i in range(5):\n",
    "            full_zero=np.zeros((128,128,5),dtype=np.float32)\n",
    "            full_zero[:,:,i]=full_one\n",
    "            self.condition128.append(full_zero)\n",
    "\n",
    "        # define label 64*64 for condition discriminate image\n",
    "        self.condition64 = []\n",
    "        full_one = np.ones((64, 64),dtype=np.float32)\n",
    "        for i in range(5):\n",
    "            full_zero = np.zeros((64, 64, 5),dtype=np.float32)\n",
    "            full_zero[:, :, i] = full_one\n",
    "            self.condition64.append(full_zero)\n",
    "\n",
    "        #define label_pairs\n",
    "        label_pair_root=\"/kaggle/input/utkpreprocess/train_label_pair.txt\"\n",
    "        with open(label_pair_root,'r') as f:\n",
    "            lines=f.readlines()\n",
    "        lines=[line.strip() for line in lines]\n",
    "        shuffle(lines)\n",
    "        self.label_pairs=[]\n",
    "        for line in lines:\n",
    "            label_pair=[]\n",
    "            items=line.split()\n",
    "            label_pair.append(int(items[0]))\n",
    "            label_pair.append(int(items[1]))\n",
    "            self.label_pairs.append(label_pair)\n",
    "\n",
    "        #define group_images\n",
    "        group_lists = [\n",
    "            os.path.join(list_root, 'train_age_group_0.txt'),\n",
    "            os.path.join(list_root, 'train_age_group_1.txt'),\n",
    "            os.path.join(list_root, 'train_age_group_2.txt'),\n",
    "            os.path.join(list_root, 'train_age_group_3.txt'),\n",
    "            os.path.join(list_root, 'train_age_group_4.txt')\n",
    "        ]\n",
    "\n",
    "        self.label_group_images = []\n",
    "        for i in range(len(group_lists)):\n",
    "            with open(group_lists[i], 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                lines = [line.strip() for line in lines]\n",
    "            group_images = []\n",
    "            for l in lines:\n",
    "                items = l.split()\n",
    "                group_images.append(os.path.join(data_root, items[0]))\n",
    "            self.label_group_images.append(group_images)\n",
    "\n",
    "        #define train.txt\n",
    "        if self.split == \"train\":\n",
    "            self.source_images = []#which use to aging transfer\n",
    "            with open(os.path.join(list_root, 'train.txt'), 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                lines = [line.strip() for line in lines]\n",
    "            shuffle(lines)\n",
    "            for l in lines:\n",
    "                items = l.split()\n",
    "                self.source_images.append(os.path.join(data_root, items[0]))\n",
    "        else:\n",
    "            self.source_images = []  # which use to aging transfer\n",
    "            with open(os.path.join(list_root, 'test.txt'), 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                lines = [line.strip() for line in lines]\n",
    "            shuffle(lines)\n",
    "            for l in lines:\n",
    "                items = l.split()\n",
    "                self.source_images.append(os.path.join(data_root, items[0]))\n",
    "\n",
    "        #define pointer\n",
    "        self.train_group_pointer=[0,0,0,0,0]\n",
    "        self.source_pointer=0\n",
    "        self.batch_size=32\n",
    "        self.transforms=transforms\n",
    "        self.label_transforms=label_transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.split == \"train\":\n",
    "            pair_idx=idx//self.batch_size #a batch train the same pair\n",
    "            true_label=int(self.label_pairs[pair_idx][0])\n",
    "            fake_label=int(self.label_pairs[pair_idx][1])\n",
    "\n",
    "            true_label_128=self.condition128[true_label]\n",
    "            true_label_64=self.condition64[true_label]\n",
    "            fake_label_64=self.condition64[fake_label]\n",
    "\n",
    "            true_label_img=pil_loader(self.label_group_images[true_label][self.train_group_pointer[true_label]]).resize((128,128))\n",
    "            source_img=pil_loader(self.source_images[self.source_pointer])\n",
    "\n",
    "            source_img_227=source_img.resize((227,227))\n",
    "            source_img_128=source_img.resize((128,128))\n",
    "\n",
    "            if self.train_group_pointer[true_label]<len(self.label_group_images[true_label])-1:\n",
    "                self.train_group_pointer[true_label]+=1\n",
    "            else:\n",
    "                self.train_group_pointer[true_label]=0\n",
    "\n",
    "            if self.source_pointer<len(self.source_images)-1:\n",
    "                self.source_pointer+=1\n",
    "            else:\n",
    "                self.source_pointer=0\n",
    "\n",
    "            if self.transforms != None:\n",
    "                true_label_img=self.transforms(true_label_img)\n",
    "                source_img_227=self.transforms(source_img_227)\n",
    "                source_img_128=self.transforms(source_img_128)\n",
    "\n",
    "            if self.label_transforms != None:\n",
    "                true_label_128=self.label_transforms(true_label_128)\n",
    "                true_label_64=self.label_transforms(true_label_64)\n",
    "                fake_label_64=self.label_transforms(fake_label_64)\n",
    "            #source img 227 : use it to extract face feature\n",
    "            #source img 128 : use it to generate different age face -> then resize to (227,227) to extract feature, compile with source img 227\n",
    "            #ture_label_img : img in target age group -> use to train discriminator\n",
    "            #true_label_128 : use this condition to generate\n",
    "            #true_label_64 and fake_label_64 : use this condition to discrimination\n",
    "            #true_label : label\n",
    "\n",
    "            return source_img_227,source_img_128,true_label_img,true_label_128,true_label_64,fake_label_64, true_label\n",
    "        else:\n",
    "            source_img_128=pil_loader(self.source_images[idx]).resize((128,128))\n",
    "            if self.transforms != None:\n",
    "                source_img_128=self.transforms(source_img_128)\n",
    "            condition_128_tensor_li=[]\n",
    "            if self.label_transforms != None:\n",
    "                for condition in self.condition128:\n",
    "                    condition_128_tensor_li.append(self.label_transforms(condition).cuda())\n",
    "            return source_img_128.cuda(),condition_128_tensor_li\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.split == \"train\":\n",
    "            return len(self.label_pairs)\n",
    "        else:\n",
    "            return len(self.source_images)\n",
    "\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "label_transforms=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "CACD_dataset=CACD(\"train\", transforms , label_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=CACD_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "for idx,(source_img_227,source_img_128,true_label_img,true_label_128,true_label_64,fake_label_64, true_label) in enumerate(train_loader):\n",
    "    print(true_label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84ad231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T16:40:07.957301Z",
     "iopub.status.busy": "2025-01-02T16:40:07.956949Z",
     "iopub.status.idle": "2025-01-02T16:40:07.963742Z",
     "shell.execute_reply": "2025-01-02T16:40:07.962775Z"
    },
    "papermill": {
     "duration": 0.012125,
     "end_time": "2025-01-02T16:40:07.965280",
     "exception": false,
     "start_time": "2025-01-02T16:40:07.953155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21093799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T16:40:07.972068Z",
     "iopub.status.busy": "2025-01-02T16:40:07.971795Z",
     "iopub.status.idle": "2025-01-02T16:40:07.988257Z",
     "shell.execute_reply": "2025-01-02T16:40:07.987268Z"
    },
    "papermill": {
     "duration": 0.021501,
     "end_time": "2025-01-02T16:40:07.989669",
     "exception": false,
     "start_time": "2025-01-02T16:40:07.968168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "import math\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.functional import pad\n",
    "from torch.nn.modules import Module\n",
    "from torch.nn.modules.utils import _single, _pair, _triple\n",
    "\n",
    "class _ConvNd(Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
    "                 padding, dilation, transposed, output_padding, groups, bias):\n",
    "        super(_ConvNd, self).__init__()\n",
    "        if in_channels % groups != 0:\n",
    "            raise ValueError('in_channels must be divisible by groups')\n",
    "        if out_channels % groups != 0:\n",
    "            raise ValueError('out_channels must be divisible by groups')\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.transposed = transposed\n",
    "        self.output_padding = output_padding\n",
    "        self.groups = groups\n",
    "        if transposed:\n",
    "            self.weight = Parameter(torch.Tensor(\n",
    "                in_channels, out_channels // groups, *kernel_size))\n",
    "        else:\n",
    "            self.weight = Parameter(torch.Tensor(\n",
    "                out_channels, in_channels // groups, *kernel_size))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        n = self.in_channels\n",
    "        for k in self.kernel_size:\n",
    "            n *= k\n",
    "        stdv = 1. / math.sqrt(n)\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = ('{name}({in_channels}, {out_channels}, kernel_size={kernel_size}'\n",
    "             ', stride={stride}')\n",
    "        if self.padding != (0,) * len(self.padding):\n",
    "            s += ', padding={padding}'\n",
    "        if self.dilation != (1,) * len(self.dilation):\n",
    "            s += ', dilation={dilation}'\n",
    "        if self.output_padding != (0,) * len(self.output_padding):\n",
    "            s += ', output_padding={output_padding}'\n",
    "        if self.groups != 1:\n",
    "            s += ', groups={groups}'\n",
    "        if self.bias is None:\n",
    "            s += ', bias=False'\n",
    "        s += ')'\n",
    "        return s.format(name=self.__class__.__name__, **self.__dict__)\n",
    "\n",
    "class Conv2d(_ConvNd):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        kernel_size = _pair(kernel_size)\n",
    "        stride = _pair(stride)\n",
    "        padding = _pair(padding)\n",
    "        dilation = _pair(dilation)\n",
    "        super(Conv2d, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation,\n",
    "            False, _pair(0), groups, bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return _conv2d_same_padding(input, self.weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "# custom conv2d, because pytorch don't have \"padding='same'\" option.\n",
    "def _conv2d_same_padding(input, weight, bias=None, stride=(1,1), padding=1, dilation=(1,1), groups=1):\n",
    "\n",
    "    input_rows = input.size(2)\n",
    "    filter_rows = weight.size(2)\n",
    "    effective_filter_size_rows = (filter_rows - 1) * dilation[0] + 1\n",
    "    out_rows = (input_rows + stride[0] - 1) // stride[0]\n",
    "    padding_needed = max(0, (out_rows - 1) * stride[0] + effective_filter_size_rows -\n",
    "                  input_rows)\n",
    "    padding_rows = max(0, (out_rows - 1) * stride[0] +\n",
    "                        (filter_rows - 1) * dilation[0] + 1 - input_rows)\n",
    "    rows_odd = (padding_rows % 2 != 0)\n",
    "    padding_cols = max(0, (out_rows - 1) * stride[0] +\n",
    "                        (filter_rows - 1) * dilation[0] + 1 - input_rows)\n",
    "    cols_odd = (padding_rows % 2 != 0)\n",
    "\n",
    "    if rows_odd or cols_odd:\n",
    "        input = pad(input, [0, int(cols_odd), 0, int(rows_odd)])\n",
    "\n",
    "    return F.conv2d(input, weight, bias, stride,\n",
    "                  padding=(padding_rows // 2, padding_cols // 2),\n",
    "                  dilation=dilation, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a6be01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T16:40:07.996110Z",
     "iopub.status.busy": "2025-01-02T16:40:07.995872Z",
     "iopub.status.idle": "2025-01-02T16:40:08.008517Z",
     "shell.execute_reply": "2025-01-02T16:40:08.007578Z"
    },
    "papermill": {
     "duration": 0.017372,
     "end_time": "2025-01-02T16:40:08.009892",
     "exception": false,
     "start_time": "2025-01-02T16:40:07.992520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PatchDiscriminator, self).__init__()\n",
    "        self.lrelu = nn.LeakyReLU(0.2)\n",
    "        self.conv1 = Conv2d(3, 64, kernel_size=4, stride=2)\n",
    "        self.conv2 = Conv2d(69, 128, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(128, eps=0.001, track_running_stats=True)\n",
    "        self.conv3 = Conv2d(128, 256, kernel_size=4, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(256, eps=0.001, track_running_stats=True)\n",
    "        self.conv4 = Conv2d(256, 512, kernel_size=4, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(512, eps=0.001, track_running_stats=True)\n",
    "        self.conv5 = Conv2d(512, 512, kernel_size=4, stride=2)\n",
    "\n",
    "    def forward(self, x,condition):\n",
    "        x = self.lrelu(self.conv1(x))\n",
    "        x=torch.cat((x,condition),1)\n",
    "        x = self.lrelu(self.bn2(self.conv2(x)))\n",
    "        x = self.lrelu(self.bn3(self.conv3(x)))\n",
    "        x = self.lrelu(self.bn4(self.conv4(x)))\n",
    "        x = self.conv5(x)\n",
    "        return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1 = Conv2d(8, 32, kernel_size=7, stride=1)\n",
    "        self.conv2 = Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.conv3 = Conv2d(64, 128, kernel_size=3, stride=2)\n",
    "        self.conv4 = Conv2d(32, 3, kernel_size=7, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32, eps=0.001, track_running_stats=True)\n",
    "        self.bn2 = nn.BatchNorm2d(64, eps=0.001, track_running_stats=True)\n",
    "        self.bn3 = nn.BatchNorm2d(128, eps=0.001, track_running_stats=True)\n",
    "        self.bn4 = nn.BatchNorm2d(64, eps=0.001, track_running_stats=True)\n",
    "        self.bn5 = nn.BatchNorm2d(32, eps=0.001, track_running_stats=True)\n",
    "        self.repeat_blocks=self._make_repeat_blocks(BasicBlock(128,128),6)\n",
    "        self.deconv1 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=0,output_padding=1)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.tanh=nn.Tanh()\n",
    "\n",
    "    def _make_repeat_blocks(self,block,repeat_times):\n",
    "        layers=[]\n",
    "        for i in range(repeat_times):\n",
    "            layers.append(block)\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x,condition=None):\n",
    "        if condition is not None:\n",
    "            x=torch.cat((x,condition),1)\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.repeat_blocks(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.relu(self.bn4(x))\n",
    "        x = self.deconv2(x)\n",
    "        x = self.relu(self.bn5(x))\n",
    "        x = self.tanh(self.conv4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3784e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T16:40:08.016521Z",
     "iopub.status.busy": "2025-01-02T16:40:08.016256Z",
     "iopub.status.idle": "2025-01-02T16:40:08.026067Z",
     "shell.execute_reply": "2025-01-02T16:40:08.025311Z"
    },
    "papermill": {
     "duration": 0.014519,
     "end_time": "2025-01-02T16:40:08.027462",
     "exception": false,
     "start_time": "2025-01-02T16:40:08.012943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CGANs:\n",
    "    def __init__(self,lr=0.01):\n",
    "\n",
    "        self.d_lr=lr\n",
    "        self.g_lr=lr\n",
    "\n",
    "        self.generator=Generator().cuda()\n",
    "        self.discriminator=PatchDiscriminator().cuda()\n",
    "\n",
    "        self.MSEloss=nn.MSELoss().cuda()\n",
    "        self.CrossEntropyLoss=nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        self.d_optim = torch.optim.Adam(self.discriminator.parameters(),self.d_lr,betas=(0.5,0.99))\n",
    "        self.g_optim = torch.optim.Adam(self.generator.parameters(), self.g_lr, betas=(0.5, 0.99))\n",
    "\n",
    "    def save_model(self,dir,filename):\n",
    "        torch.save(self.generator.state_dict(),os.path.join(dir,\"g\"+filename))\n",
    "        torch.save(self.discriminator.state_dict(),os.path.join(dir,\"d\"+filename))\n",
    "\n",
    "    def load_generator_state_dict(self,state_dict):\n",
    "        pretrained_dict = state_dict\n",
    "        # step2: get model state_dict\n",
    "        model_dict = self.generator.state_dict()\n",
    "        # step3: remove pretrained_dict params which is not in model_dict\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        # step4: update model_dict using pretrained_dict\n",
    "        model_dict.update(pretrained_dict)\n",
    "        # step5: update model using model_dict\n",
    "        self.generator.load_state_dict(model_dict)\n",
    "\n",
    "    def test_generate(self,source_img_128,condition):\n",
    "        self.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            generate_image=self.generator(source_img_128,condition)\n",
    "        return generate_image\n",
    "\n",
    "    def cuda(self):\n",
    "        self.generator=self.generator.cuda()\n",
    "\n",
    "    def train(self,source_img_227,source_img_128,true_label_img,true_label_128,true_label_64,fake_label_64, age_label):\n",
    "        '''\n",
    "\n",
    "        :param source_img_227: use this img to extract conv5 feature\n",
    "        :param source_img_128: use this img to generate face in target age\n",
    "        :param true_label_img:\n",
    "        :param true_label_128:\n",
    "        :param true_label_64:\n",
    "        :param fake_label_64:\n",
    "        :param age_label:\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        ###################################gan_loss###############################\n",
    "        self.g_source=self.generator(source_img_128,condition=true_label_128)\n",
    "\n",
    "        #real img, right age label\n",
    "        #logit means prob which hasn't been normalized\n",
    "\n",
    "        #d1 logit ,discriminator 1 means true,0 means false.\n",
    "        d1_logit=self.discriminator(true_label_img,condition=true_label_64)\n",
    "\n",
    "        d1_real_loss=self.MSEloss(d1_logit,torch.ones((d1_logit.size())).cuda())\n",
    "\n",
    "        #real img, false label\n",
    "        d2_logit=self.discriminator(true_label_img,condition=fake_label_64)\n",
    "        d2_fake_loss=self.MSEloss(d2_logit,torch.zeros((d1_logit.size())).cuda())\n",
    "\n",
    "        #fake img,real label\n",
    "        d3_logit=self.discriminator(self.g_source,condition=true_label_64)\n",
    "        d3_fake_loss=self.MSEloss(d3_logit,torch.zeros((d1_logit.size())).cuda())#use this for discriminator\n",
    "        d3_real_loss=self.MSEloss(d3_logit,torch.ones((d1_logit.size())).cuda())#use this for genrator\n",
    "\n",
    "        self.d_loss=1./2 * (d1_real_loss + 1. / 2 * (d2_fake_loss + d3_fake_loss))\n",
    "        self.g_loss=1./2*d3_real_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3b57237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T16:40:08.034452Z",
     "iopub.status.busy": "2025-01-02T16:40:08.034132Z",
     "iopub.status.idle": "2025-01-03T01:30:37.504801Z",
     "shell.execute_reply": "2025-01-03T01:30:37.503818Z"
    },
    "papermill": {
     "duration": 31829.476132,
     "end_time": "2025-01-03T01:30:37.506691",
     "exception": false,
     "start_time": "2025-01-02T16:40:08.030559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to train:\n",
      "\n",
      "epoch: 0\n",
      "step 100/1407, g_loss = 0.174, d_loss = 0.228\n",
      "step 200/1407, g_loss = 0.197, d_loss = 0.194\n",
      "step 300/1407, g_loss = 0.215, d_loss = 0.267\n",
      "step 400/1407, g_loss = 0.234, d_loss = 0.176\n",
      "step 500/1407, g_loss = 0.189, d_loss = 0.262\n",
      "step 600/1407, g_loss = 0.176, d_loss = 0.174\n",
      "step 700/1407, g_loss = 0.240, d_loss = 0.207\n",
      "step 800/1407, g_loss = 0.164, d_loss = 0.246\n",
      "step 900/1407, g_loss = 0.171, d_loss = 0.203\n",
      "step 1000/1407, g_loss = 0.225, d_loss = 0.163\n",
      "step 1100/1407, g_loss = 0.170, d_loss = 0.173\n",
      "step 1200/1407, g_loss = 0.168, d_loss = 0.152\n",
      "step 1300/1407, g_loss = 0.158, d_loss = 0.229\n",
      "step 1400/1407, g_loss = 0.216, d_loss = 0.219\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 1\n",
      "step 100/1407, g_loss = 0.235, d_loss = 0.224\n",
      "step 200/1407, g_loss = 0.272, d_loss = 0.154\n",
      "step 300/1407, g_loss = 0.218, d_loss = 0.219\n",
      "step 400/1407, g_loss = 0.248, d_loss = 0.134\n",
      "step 500/1407, g_loss = 0.205, d_loss = 0.171\n",
      "step 600/1407, g_loss = 0.245, d_loss = 0.205\n",
      "step 700/1407, g_loss = 0.232, d_loss = 0.111\n",
      "step 800/1407, g_loss = 0.293, d_loss = 0.127\n",
      "step 900/1407, g_loss = 0.211, d_loss = 0.126\n",
      "step 1000/1407, g_loss = 0.202, d_loss = 0.169\n",
      "step 1100/1407, g_loss = 0.287, d_loss = 0.154\n",
      "step 1200/1407, g_loss = 0.267, d_loss = 0.252\n",
      "step 1300/1407, g_loss = 0.231, d_loss = 0.198\n",
      "step 1400/1407, g_loss = 0.303, d_loss = 0.145\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:26<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 2\n",
      "step 100/1407, g_loss = 0.207, d_loss = 0.116\n",
      "step 200/1407, g_loss = 0.208, d_loss = 0.154\n",
      "step 300/1407, g_loss = 0.199, d_loss = 0.159\n",
      "step 400/1407, g_loss = 0.293, d_loss = 0.150\n",
      "step 500/1407, g_loss = 0.271, d_loss = 0.177\n",
      "step 600/1407, g_loss = 0.186, d_loss = 0.139\n",
      "step 700/1407, g_loss = 0.167, d_loss = 0.144\n",
      "step 800/1407, g_loss = 0.224, d_loss = 0.164\n",
      "step 900/1407, g_loss = 0.246, d_loss = 0.117\n",
      "step 1000/1407, g_loss = 0.270, d_loss = 0.124\n",
      "step 1100/1407, g_loss = 0.278, d_loss = 0.267\n",
      "step 1200/1407, g_loss = 0.256, d_loss = 0.136\n",
      "step 1300/1407, g_loss = 0.297, d_loss = 0.187\n",
      "step 1400/1407, g_loss = 0.196, d_loss = 0.134\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:28<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 3\n",
      "step 100/1407, g_loss = 0.285, d_loss = 0.099\n",
      "step 200/1407, g_loss = 0.275, d_loss = 0.259\n",
      "step 300/1407, g_loss = 0.216, d_loss = 0.147\n",
      "step 400/1407, g_loss = 0.237, d_loss = 0.103\n",
      "step 500/1407, g_loss = 0.348, d_loss = 0.181\n",
      "step 600/1407, g_loss = 0.260, d_loss = 0.132\n",
      "step 700/1407, g_loss = 0.224, d_loss = 0.121\n",
      "step 800/1407, g_loss = 0.234, d_loss = 0.096\n",
      "step 900/1407, g_loss = 0.254, d_loss = 0.140\n",
      "step 1000/1407, g_loss = 0.217, d_loss = 0.119\n",
      "step 1100/1407, g_loss = 0.190, d_loss = 0.124\n",
      "step 1200/1407, g_loss = 0.230, d_loss = 0.224\n",
      "step 1300/1407, g_loss = 0.204, d_loss = 0.098\n",
      "step 1400/1407, g_loss = 0.234, d_loss = 0.119\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:27<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 4\n",
      "step 100/1407, g_loss = 0.299, d_loss = 0.184\n",
      "step 200/1407, g_loss = 0.243, d_loss = 0.165\n",
      "step 300/1407, g_loss = 0.367, d_loss = 0.273\n",
      "step 400/1407, g_loss = 0.183, d_loss = 0.134\n",
      "step 500/1407, g_loss = 0.239, d_loss = 0.134\n",
      "step 600/1407, g_loss = 0.203, d_loss = 0.123\n",
      "step 700/1407, g_loss = 0.250, d_loss = 0.102\n",
      "step 800/1407, g_loss = 0.229, d_loss = 0.116\n",
      "step 900/1407, g_loss = 0.161, d_loss = 0.128\n",
      "step 1000/1407, g_loss = 0.255, d_loss = 0.168\n",
      "step 1100/1407, g_loss = 0.217, d_loss = 0.128\n",
      "step 1200/1407, g_loss = 0.235, d_loss = 0.130\n",
      "step 1300/1407, g_loss = 0.222, d_loss = 0.188\n",
      "step 1400/1407, g_loss = 0.197, d_loss = 0.118\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:28<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 5\n",
      "step 100/1407, g_loss = 0.251, d_loss = 0.183\n",
      "step 200/1407, g_loss = 0.291, d_loss = 0.115\n",
      "step 300/1407, g_loss = 0.246, d_loss = 0.093\n",
      "step 400/1407, g_loss = 0.264, d_loss = 0.142\n",
      "step 500/1407, g_loss = 0.243, d_loss = 0.132\n",
      "step 600/1407, g_loss = 0.273, d_loss = 0.222\n",
      "step 700/1407, g_loss = 0.337, d_loss = 0.072\n",
      "step 800/1407, g_loss = 0.244, d_loss = 0.119\n",
      "step 900/1407, g_loss = 0.272, d_loss = 0.079\n",
      "step 1000/1407, g_loss = 0.276, d_loss = 0.127\n",
      "step 1100/1407, g_loss = 0.316, d_loss = 0.091\n",
      "step 1200/1407, g_loss = 0.226, d_loss = 0.183\n",
      "step 1300/1407, g_loss = 0.218, d_loss = 0.117\n",
      "step 1400/1407, g_loss = 0.221, d_loss = 0.126\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:36<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 6\n",
      "step 100/1407, g_loss = 0.231, d_loss = 0.121\n",
      "step 200/1407, g_loss = 0.269, d_loss = 0.121\n",
      "step 300/1407, g_loss = 0.254, d_loss = 0.107\n",
      "step 400/1407, g_loss = 0.237, d_loss = 0.081\n",
      "step 500/1407, g_loss = 0.362, d_loss = 0.207\n",
      "step 600/1407, g_loss = 0.300, d_loss = 0.092\n",
      "step 700/1407, g_loss = 0.236, d_loss = 0.097\n",
      "step 800/1407, g_loss = 0.281, d_loss = 0.100\n",
      "step 900/1407, g_loss = 0.258, d_loss = 0.094\n",
      "step 1000/1407, g_loss = 0.268, d_loss = 0.098\n",
      "step 1100/1407, g_loss = 0.324, d_loss = 0.180\n",
      "step 1200/1407, g_loss = 0.172, d_loss = 0.124\n",
      "step 1300/1407, g_loss = 0.254, d_loss = 0.129\n",
      "step 1400/1407, g_loss = 0.332, d_loss = 0.135\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:26<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 7\n",
      "step 100/1407, g_loss = 0.244, d_loss = 0.097\n",
      "step 200/1407, g_loss = 0.295, d_loss = 0.141\n",
      "step 300/1407, g_loss = 0.279, d_loss = 0.090\n",
      "step 400/1407, g_loss = 0.237, d_loss = 0.116\n",
      "step 500/1407, g_loss = 0.523, d_loss = 0.161\n",
      "step 600/1407, g_loss = 0.258, d_loss = 0.085\n",
      "step 700/1407, g_loss = 0.320, d_loss = 0.167\n",
      "step 800/1407, g_loss = 0.230, d_loss = 0.100\n",
      "step 900/1407, g_loss = 0.280, d_loss = 0.073\n",
      "step 1000/1407, g_loss = 0.279, d_loss = 0.128\n",
      "step 1100/1407, g_loss = 0.235, d_loss = 0.108\n",
      "step 1200/1407, g_loss = 0.262, d_loss = 0.092\n",
      "step 1300/1407, g_loss = 0.290, d_loss = 0.098\n",
      "step 1400/1407, g_loss = 0.237, d_loss = 0.152\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:30<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 8\n",
      "step 100/1407, g_loss = 0.252, d_loss = 0.158\n",
      "step 200/1407, g_loss = 0.294, d_loss = 0.264\n",
      "step 300/1407, g_loss = 0.339, d_loss = 0.078\n",
      "step 400/1407, g_loss = 0.292, d_loss = 0.078\n",
      "step 500/1407, g_loss = 0.329, d_loss = 0.103\n",
      "step 600/1407, g_loss = 0.399, d_loss = 0.113\n",
      "step 700/1407, g_loss = 0.271, d_loss = 0.124\n",
      "step 800/1407, g_loss = 0.304, d_loss = 0.115\n",
      "step 900/1407, g_loss = 0.366, d_loss = 0.092\n",
      "step 1000/1407, g_loss = 0.270, d_loss = 0.089\n",
      "step 1100/1407, g_loss = 0.336, d_loss = 0.074\n",
      "step 1200/1407, g_loss = 0.424, d_loss = 0.148\n",
      "step 1300/1407, g_loss = 0.310, d_loss = 0.165\n",
      "step 1400/1407, g_loss = 0.403, d_loss = 0.114\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:27<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 9\n",
      "step 100/1407, g_loss = 0.426, d_loss = 0.065\n",
      "step 200/1407, g_loss = 0.358, d_loss = 0.122\n",
      "step 300/1407, g_loss = 0.287, d_loss = 0.090\n",
      "step 400/1407, g_loss = 0.305, d_loss = 0.096\n",
      "step 500/1407, g_loss = 0.306, d_loss = 0.087\n",
      "step 600/1407, g_loss = 0.423, d_loss = 0.180\n",
      "step 700/1407, g_loss = 0.323, d_loss = 0.062\n",
      "step 800/1407, g_loss = 0.397, d_loss = 0.170\n",
      "step 900/1407, g_loss = 0.313, d_loss = 0.123\n",
      "step 1000/1407, g_loss = 0.313, d_loss = 0.088\n",
      "step 1100/1407, g_loss = 0.285, d_loss = 0.111\n",
      "step 1200/1407, g_loss = 0.438, d_loss = 0.060\n",
      "step 1300/1407, g_loss = 0.367, d_loss = 0.061\n",
      "step 1400/1407, g_loss = 0.384, d_loss = 0.105\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:27<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 10\n",
      "step 100/1407, g_loss = 0.346, d_loss = 0.086\n",
      "step 200/1407, g_loss = 0.321, d_loss = 0.104\n",
      "step 300/1407, g_loss = 0.354, d_loss = 0.069\n",
      "step 400/1407, g_loss = 0.346, d_loss = 0.094\n",
      "step 500/1407, g_loss = 0.353, d_loss = 0.112\n",
      "step 600/1407, g_loss = 0.464, d_loss = 0.075\n",
      "step 700/1407, g_loss = 0.334, d_loss = 0.082\n",
      "step 800/1407, g_loss = 0.461, d_loss = 0.128\n",
      "step 900/1407, g_loss = 0.357, d_loss = 0.077\n",
      "step 1000/1407, g_loss = 0.316, d_loss = 0.068\n",
      "step 1100/1407, g_loss = 0.524, d_loss = 0.104\n",
      "step 1200/1407, g_loss = 0.379, d_loss = 0.086\n",
      "step 1300/1407, g_loss = 0.346, d_loss = 0.173\n",
      "step 1400/1407, g_loss = 0.296, d_loss = 0.068\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:26<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 11\n",
      "step 100/1407, g_loss = 0.382, d_loss = 0.094\n",
      "step 200/1407, g_loss = 0.364, d_loss = 0.052\n",
      "step 300/1407, g_loss = 0.445, d_loss = 0.097\n",
      "step 400/1407, g_loss = 0.473, d_loss = 0.074\n",
      "step 500/1407, g_loss = 0.615, d_loss = 0.190\n",
      "step 600/1407, g_loss = 0.413, d_loss = 0.102\n",
      "step 700/1407, g_loss = 0.362, d_loss = 0.054\n",
      "step 800/1407, g_loss = 0.397, d_loss = 0.121\n",
      "step 900/1407, g_loss = 0.357, d_loss = 0.095\n",
      "step 1000/1407, g_loss = 0.469, d_loss = 0.067\n",
      "step 1100/1407, g_loss = 0.406, d_loss = 0.098\n",
      "step 1200/1407, g_loss = 0.323, d_loss = 0.064\n",
      "step 1300/1407, g_loss = 0.361, d_loss = 0.049\n",
      "step 1400/1407, g_loss = 0.376, d_loss = 0.093\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:28<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 12\n",
      "step 100/1407, g_loss = 0.336, d_loss = 0.059\n",
      "step 200/1407, g_loss = 0.437, d_loss = 0.039\n",
      "step 300/1407, g_loss = 0.354, d_loss = 0.055\n",
      "step 400/1407, g_loss = 0.359, d_loss = 0.085\n",
      "step 500/1407, g_loss = 0.297, d_loss = 0.061\n",
      "step 600/1407, g_loss = 0.406, d_loss = 0.104\n",
      "step 700/1407, g_loss = 0.357, d_loss = 0.080\n",
      "step 800/1407, g_loss = 0.354, d_loss = 0.055\n",
      "step 900/1407, g_loss = 0.374, d_loss = 0.040\n",
      "step 1000/1407, g_loss = 0.504, d_loss = 0.101\n",
      "step 1100/1407, g_loss = 0.439, d_loss = 0.053\n",
      "step 1200/1407, g_loss = 0.397, d_loss = 0.086\n",
      "step 1300/1407, g_loss = 0.324, d_loss = 0.067\n",
      "step 1400/1407, g_loss = 0.466, d_loss = 0.179\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:27<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 13\n",
      "step 100/1407, g_loss = 0.445, d_loss = 0.044\n",
      "step 200/1407, g_loss = 0.436, d_loss = 0.100\n",
      "step 300/1407, g_loss = 0.404, d_loss = 0.046\n",
      "step 400/1407, g_loss = 0.383, d_loss = 0.060\n",
      "step 500/1407, g_loss = 0.305, d_loss = 0.077\n",
      "step 600/1407, g_loss = 0.361, d_loss = 0.056\n",
      "step 700/1407, g_loss = 0.391, d_loss = 0.074\n",
      "step 800/1407, g_loss = 0.394, d_loss = 0.066\n",
      "step 900/1407, g_loss = 0.455, d_loss = 0.176\n",
      "step 1000/1407, g_loss = 0.354, d_loss = 0.057\n",
      "step 1100/1407, g_loss = 0.327, d_loss = 0.056\n",
      "step 1200/1407, g_loss = 0.351, d_loss = 0.086\n",
      "step 1300/1407, g_loss = 0.496, d_loss = 0.066\n",
      "step 1400/1407, g_loss = 0.420, d_loss = 0.075\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:27<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 14\n",
      "step 100/1407, g_loss = 0.487, d_loss = 0.130\n",
      "step 200/1407, g_loss = 0.402, d_loss = 0.063\n",
      "step 300/1407, g_loss = 0.433, d_loss = 0.082\n",
      "step 400/1407, g_loss = 0.431, d_loss = 0.049\n",
      "step 500/1407, g_loss = 0.434, d_loss = 0.092\n",
      "step 600/1407, g_loss = 0.404, d_loss = 0.068\n",
      "step 700/1407, g_loss = 0.494, d_loss = 0.160\n",
      "step 800/1407, g_loss = 0.431, d_loss = 0.104\n",
      "step 900/1407, g_loss = 0.499, d_loss = 0.070\n",
      "step 1000/1407, g_loss = 0.468, d_loss = 0.055\n",
      "step 1100/1407, g_loss = 0.409, d_loss = 0.078\n",
      "step 1200/1407, g_loss = 0.427, d_loss = 0.065\n",
      "step 1300/1407, g_loss = 0.417, d_loss = 0.084\n",
      "step 1400/1407, g_loss = 0.481, d_loss = 0.077\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:30<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 15\n",
      "step 100/1407, g_loss = 0.416, d_loss = 0.055\n",
      "step 200/1407, g_loss = 0.351, d_loss = 0.054\n",
      "step 300/1407, g_loss = 0.481, d_loss = 0.057\n",
      "step 400/1407, g_loss = 0.410, d_loss = 0.038\n",
      "step 500/1407, g_loss = 0.292, d_loss = 0.081\n",
      "step 600/1407, g_loss = 0.394, d_loss = 0.067\n",
      "step 700/1407, g_loss = 0.489, d_loss = 0.066\n",
      "step 800/1407, g_loss = 0.463, d_loss = 0.097\n",
      "step 900/1407, g_loss = 0.335, d_loss = 0.073\n",
      "step 1000/1407, g_loss = 0.535, d_loss = 0.073\n",
      "step 1100/1407, g_loss = 0.399, d_loss = 0.064\n",
      "step 1200/1407, g_loss = 0.426, d_loss = 0.061\n",
      "step 1300/1407, g_loss = 0.467, d_loss = 0.054\n",
      "step 1400/1407, g_loss = 0.407, d_loss = 0.042\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:30<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 16\n",
      "step 100/1407, g_loss = 0.372, d_loss = 0.065\n",
      "step 200/1407, g_loss = 0.544, d_loss = 0.085\n",
      "step 300/1407, g_loss = 0.460, d_loss = 0.076\n",
      "step 400/1407, g_loss = 0.397, d_loss = 0.049\n",
      "step 500/1407, g_loss = 0.440, d_loss = 0.063\n",
      "step 600/1407, g_loss = 0.431, d_loss = 0.050\n",
      "step 700/1407, g_loss = 0.348, d_loss = 0.060\n",
      "step 800/1407, g_loss = 0.417, d_loss = 0.124\n",
      "step 900/1407, g_loss = 0.423, d_loss = 0.033\n",
      "step 1000/1407, g_loss = 0.441, d_loss = 0.048\n",
      "step 1100/1407, g_loss = 0.416, d_loss = 0.075\n",
      "step 1200/1407, g_loss = 0.464, d_loss = 0.052\n",
      "step 1300/1407, g_loss = 0.420, d_loss = 0.072\n",
      "step 1400/1407, g_loss = 0.469, d_loss = 0.065\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:26<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 17\n",
      "step 100/1407, g_loss = 0.365, d_loss = 0.042\n",
      "step 200/1407, g_loss = 0.541, d_loss = 0.052\n",
      "step 300/1407, g_loss = 0.491, d_loss = 0.103\n",
      "step 400/1407, g_loss = 0.416, d_loss = 0.039\n",
      "step 500/1407, g_loss = 0.373, d_loss = 0.056\n",
      "step 600/1407, g_loss = 0.488, d_loss = 0.056\n",
      "step 700/1407, g_loss = 0.380, d_loss = 0.042\n",
      "step 800/1407, g_loss = 0.470, d_loss = 0.049\n",
      "step 900/1407, g_loss = 0.443, d_loss = 0.066\n",
      "step 1000/1407, g_loss = 0.478, d_loss = 0.049\n",
      "step 1100/1407, g_loss = 0.403, d_loss = 0.057\n",
      "step 1200/1407, g_loss = 0.480, d_loss = 0.112\n",
      "step 1300/1407, g_loss = 0.424, d_loss = 0.054\n",
      "step 1400/1407, g_loss = 0.454, d_loss = 0.037\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:30<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 18\n",
      "step 100/1407, g_loss = 0.483, d_loss = 0.060\n",
      "step 200/1407, g_loss = 0.423, d_loss = 0.034\n",
      "step 300/1407, g_loss = 0.454, d_loss = 0.120\n",
      "step 400/1407, g_loss = 0.404, d_loss = 0.070\n",
      "step 500/1407, g_loss = 0.402, d_loss = 0.065\n",
      "step 600/1407, g_loss = 0.409, d_loss = 0.046\n",
      "step 700/1407, g_loss = 0.443, d_loss = 0.038\n",
      "step 800/1407, g_loss = 0.457, d_loss = 0.071\n",
      "step 900/1407, g_loss = 0.452, d_loss = 0.048\n",
      "step 1000/1407, g_loss = 0.460, d_loss = 0.043\n",
      "step 1100/1407, g_loss = 0.496, d_loss = 0.060\n",
      "step 1200/1407, g_loss = 0.419, d_loss = 0.099\n",
      "step 1300/1407, g_loss = 0.434, d_loss = 0.041\n",
      "step 1400/1407, g_loss = 0.578, d_loss = 0.094\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:30<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 19\n",
      "step 100/1407, g_loss = 0.497, d_loss = 0.044\n",
      "step 200/1407, g_loss = 0.380, d_loss = 0.053\n",
      "step 300/1407, g_loss = 0.467, d_loss = 0.066\n",
      "step 400/1407, g_loss = 0.266, d_loss = 0.146\n",
      "step 500/1407, g_loss = 0.438, d_loss = 0.040\n",
      "step 600/1407, g_loss = 0.463, d_loss = 0.032\n",
      "step 700/1407, g_loss = 0.507, d_loss = 0.066\n",
      "step 800/1407, g_loss = 0.465, d_loss = 0.063\n",
      "step 900/1407, g_loss = 0.406, d_loss = 0.050\n",
      "step 1000/1407, g_loss = 0.415, d_loss = 0.079\n",
      "step 1100/1407, g_loss = 0.436, d_loss = 0.183\n",
      "step 1200/1407, g_loss = 0.402, d_loss = 0.033\n",
      "step 1300/1407, g_loss = 0.513, d_loss = 0.077\n",
      "step 1400/1407, g_loss = 0.475, d_loss = 0.030\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:30<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 20\n",
      "step 100/1407, g_loss = 0.486, d_loss = 0.086\n",
      "step 200/1407, g_loss = 0.482, d_loss = 0.030\n",
      "step 300/1407, g_loss = 0.429, d_loss = 0.047\n",
      "step 400/1407, g_loss = 0.425, d_loss = 0.036\n",
      "step 500/1407, g_loss = 0.541, d_loss = 0.050\n",
      "step 600/1407, g_loss = 0.450, d_loss = 0.038\n",
      "step 700/1407, g_loss = 0.493, d_loss = 0.050\n",
      "step 800/1407, g_loss = 0.419, d_loss = 0.075\n",
      "step 900/1407, g_loss = 0.402, d_loss = 0.065\n",
      "step 1000/1407, g_loss = 0.457, d_loss = 0.043\n",
      "step 1100/1407, g_loss = 0.497, d_loss = 0.040\n",
      "step 1200/1407, g_loss = 0.477, d_loss = 0.050\n",
      "step 1300/1407, g_loss = 0.447, d_loss = 0.048\n",
      "step 1400/1407, g_loss = 0.628, d_loss = 0.172\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:31<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 21\n",
      "step 100/1407, g_loss = 0.486, d_loss = 0.062\n",
      "step 200/1407, g_loss = 0.430, d_loss = 0.057\n",
      "step 300/1407, g_loss = 0.463, d_loss = 0.030\n",
      "step 400/1407, g_loss = 0.513, d_loss = 0.050\n",
      "step 500/1407, g_loss = 0.520, d_loss = 0.044\n",
      "step 600/1407, g_loss = 0.480, d_loss = 0.083\n",
      "step 700/1407, g_loss = 0.463, d_loss = 0.041\n",
      "step 800/1407, g_loss = 0.427, d_loss = 0.045\n",
      "step 900/1407, g_loss = 0.469, d_loss = 0.081\n",
      "step 1000/1407, g_loss = 0.417, d_loss = 0.035\n",
      "step 1100/1407, g_loss = 0.435, d_loss = 0.041\n",
      "step 1200/1407, g_loss = 0.425, d_loss = 0.055\n",
      "step 1300/1407, g_loss = 0.548, d_loss = 0.045\n",
      "step 1400/1407, g_loss = 0.434, d_loss = 0.041\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:30<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 22\n",
      "step 100/1407, g_loss = 0.424, d_loss = 0.033\n",
      "step 200/1407, g_loss = 0.416, d_loss = 0.040\n",
      "step 300/1407, g_loss = 0.427, d_loss = 0.035\n",
      "step 400/1407, g_loss = 0.499, d_loss = 0.049\n",
      "step 500/1407, g_loss = 0.438, d_loss = 0.036\n",
      "step 600/1407, g_loss = 0.575, d_loss = 0.101\n",
      "step 700/1407, g_loss = 0.424, d_loss = 0.031\n",
      "step 800/1407, g_loss = 0.476, d_loss = 0.033\n",
      "step 900/1407, g_loss = 0.548, d_loss = 0.113\n",
      "step 1000/1407, g_loss = 0.508, d_loss = 0.049\n",
      "step 1100/1407, g_loss = 0.490, d_loss = 0.054\n",
      "step 1200/1407, g_loss = 0.408, d_loss = 0.041\n",
      "step 1300/1407, g_loss = 0.551, d_loss = 0.108\n",
      "step 1400/1407, g_loss = 0.472, d_loss = 0.030\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:30<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 23\n",
      "step 100/1407, g_loss = 0.497, d_loss = 0.043\n",
      "step 200/1407, g_loss = 0.451, d_loss = 0.050\n",
      "step 300/1407, g_loss = 0.444, d_loss = 0.063\n",
      "step 400/1407, g_loss = 0.517, d_loss = 0.031\n",
      "step 500/1407, g_loss = 0.693, d_loss = 0.140\n",
      "step 600/1407, g_loss = 0.482, d_loss = 0.030\n",
      "step 700/1407, g_loss = 0.458, d_loss = 0.057\n",
      "step 800/1407, g_loss = 0.474, d_loss = 0.040\n",
      "step 900/1407, g_loss = 0.471, d_loss = 0.054\n",
      "step 1000/1407, g_loss = 0.537, d_loss = 0.100\n",
      "step 1100/1407, g_loss = 0.435, d_loss = 0.038\n",
      "step 1200/1407, g_loss = 0.447, d_loss = 0.040\n",
      "step 1300/1407, g_loss = 0.488, d_loss = 0.034\n",
      "step 1400/1407, g_loss = 0.509, d_loss = 0.041\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:30<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 24\n",
      "step 100/1407, g_loss = 0.482, d_loss = 0.059\n",
      "step 200/1407, g_loss = 0.500, d_loss = 0.047\n",
      "step 300/1407, g_loss = 0.488, d_loss = 0.055\n",
      "step 400/1407, g_loss = 0.469, d_loss = 0.067\n",
      "step 500/1407, g_loss = 0.431, d_loss = 0.028\n",
      "step 600/1407, g_loss = 0.424, d_loss = 0.033\n",
      "step 700/1407, g_loss = 0.472, d_loss = 0.030\n",
      "step 800/1407, g_loss = 0.473, d_loss = 0.047\n",
      "step 900/1407, g_loss = 0.447, d_loss = 0.032\n",
      "step 1000/1407, g_loss = 0.480, d_loss = 0.029\n",
      "step 1100/1407, g_loss = 0.458, d_loss = 0.057\n",
      "step 1200/1407, g_loss = 0.500, d_loss = 0.035\n",
      "step 1300/1407, g_loss = 0.536, d_loss = 0.047\n",
      "step 1400/1407, g_loss = 0.583, d_loss = 0.072\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:26<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 25\n",
      "step 100/1407, g_loss = 0.477, d_loss = 0.033\n",
      "step 200/1407, g_loss = 0.436, d_loss = 0.045\n",
      "step 300/1407, g_loss = 0.525, d_loss = 0.031\n",
      "step 400/1407, g_loss = 0.465, d_loss = 0.027\n",
      "step 500/1407, g_loss = 0.468, d_loss = 0.034\n",
      "step 600/1407, g_loss = 0.477, d_loss = 0.032\n",
      "step 700/1407, g_loss = 0.448, d_loss = 0.031\n",
      "step 800/1407, g_loss = 0.485, d_loss = 0.033\n",
      "step 900/1407, g_loss = 0.529, d_loss = 0.035\n",
      "step 1000/1407, g_loss = 0.507, d_loss = 0.029\n",
      "step 1100/1407, g_loss = 0.569, d_loss = 0.049\n",
      "step 1200/1407, g_loss = 0.525, d_loss = 0.083\n",
      "step 1300/1407, g_loss = 0.471, d_loss = 0.027\n",
      "step 1400/1407, g_loss = 0.442, d_loss = 0.041\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:29<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 26\n",
      "step 100/1407, g_loss = 0.438, d_loss = 0.036\n",
      "step 200/1407, g_loss = 0.533, d_loss = 0.077\n",
      "step 300/1407, g_loss = 0.535, d_loss = 0.058\n",
      "step 400/1407, g_loss = 0.493, d_loss = 0.026\n",
      "step 500/1407, g_loss = 0.524, d_loss = 0.057\n",
      "step 600/1407, g_loss = 0.478, d_loss = 0.023\n",
      "step 700/1407, g_loss = 0.460, d_loss = 0.023\n",
      "step 800/1407, g_loss = 0.524, d_loss = 0.027\n",
      "step 900/1407, g_loss = 0.521, d_loss = 0.054\n",
      "step 1000/1407, g_loss = 0.453, d_loss = 0.030\n",
      "step 1100/1407, g_loss = 0.559, d_loss = 0.113\n",
      "step 1200/1407, g_loss = 0.627, d_loss = 0.030\n",
      "step 1300/1407, g_loss = 0.538, d_loss = 0.047\n",
      "step 1400/1407, g_loss = 0.448, d_loss = 0.023\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:27<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 27\n",
      "step 100/1407, g_loss = 0.508, d_loss = 0.038\n",
      "step 200/1407, g_loss = 0.452, d_loss = 0.026\n",
      "step 300/1407, g_loss = 0.518, d_loss = 0.041\n",
      "step 400/1407, g_loss = 0.503, d_loss = 0.032\n",
      "step 500/1407, g_loss = 0.488, d_loss = 0.042\n",
      "step 600/1407, g_loss = 0.499, d_loss = 0.024\n",
      "step 700/1407, g_loss = 0.486, d_loss = 0.026\n",
      "step 800/1407, g_loss = 0.504, d_loss = 0.061\n",
      "step 900/1407, g_loss = 0.599, d_loss = 0.101\n",
      "step 1000/1407, g_loss = 0.561, d_loss = 0.041\n",
      "step 1100/1407, g_loss = 0.533, d_loss = 0.041\n",
      "step 1200/1407, g_loss = 0.421, d_loss = 0.035\n",
      "step 1300/1407, g_loss = 0.461, d_loss = 0.032\n",
      "step 1400/1407, g_loss = 0.466, d_loss = 0.026\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:26<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 28\n",
      "step 100/1407, g_loss = 0.489, d_loss = 0.021\n",
      "step 200/1407, g_loss = 0.460, d_loss = 0.026\n",
      "step 300/1407, g_loss = 0.577, d_loss = 0.082\n",
      "step 400/1407, g_loss = 0.507, d_loss = 0.035\n",
      "step 500/1407, g_loss = 0.516, d_loss = 0.056\n",
      "step 600/1407, g_loss = 0.486, d_loss = 0.039\n",
      "step 700/1407, g_loss = 0.501, d_loss = 0.062\n",
      "step 800/1407, g_loss = 0.520, d_loss = 0.028\n",
      "step 900/1407, g_loss = 0.547, d_loss = 0.049\n",
      "step 1000/1407, g_loss = 0.444, d_loss = 0.028\n",
      "step 1100/1407, g_loss = 0.492, d_loss = 0.059\n",
      "step 1200/1407, g_loss = 0.467, d_loss = 0.024\n",
      "step 1300/1407, g_loss = 0.445, d_loss = 0.029\n",
      "step 1400/1407, g_loss = 0.513, d_loss = 0.040\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:27<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n",
      "epoch: 29\n",
      "step 100/1407, g_loss = 0.552, d_loss = 0.073\n",
      "step 200/1407, g_loss = 0.527, d_loss = 0.045\n",
      "step 300/1407, g_loss = 0.463, d_loss = 0.026\n",
      "step 400/1407, g_loss = 0.581, d_loss = 0.057\n",
      "step 500/1407, g_loss = 0.475, d_loss = 0.022\n",
      "step 600/1407, g_loss = 0.562, d_loss = 0.038\n",
      "step 700/1407, g_loss = 0.491, d_loss = 0.017\n",
      "step 800/1407, g_loss = 0.491, d_loss = 0.022\n",
      "step 900/1407, g_loss = 0.464, d_loss = 0.026\n",
      "step 1000/1407, g_loss = 0.580, d_loss = 0.059\n",
      "step 1100/1407, g_loss = 0.532, d_loss = 0.043\n",
      "step 1200/1407, g_loss = 0.578, d_loss = 0.043\n",
      "step 1300/1407, g_loss = 0.532, d_loss = 0.033\n",
      "step 1400/1407, g_loss = 0.508, d_loss = 0.034\n",
      "checkpoint has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:34<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image has been created!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "max_epoches = 30\n",
    "val_interval = 1400 #Number of steps to validate\n",
    "save_interval = 1400 #Number of batches to save model\n",
    "\n",
    "d_iters = 2 \n",
    "g_iters = 1 \n",
    "\n",
    "#model\n",
    "age_groups = 5\n",
    "\n",
    "#data, io\n",
    "checkpoint = \"/kaggle/working/checkpoint/\"\n",
    "saved_model_folder = \"/kaggle/working/checkpoint/saved_parameters/\"\n",
    "saved_validation_folder = \"/kaggle/working/checkpoint/validation/\"\n",
    "\n",
    "#check_dir\n",
    "check_dir(checkpoint)\n",
    "check_dir(saved_model_folder)\n",
    "check_dir(saved_validation_folder)\n",
    "\n",
    "def main():\n",
    "    print(\"Start to train:\\n\")\n",
    "\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        Img_to_zero_center()\n",
    "    ])\n",
    "    label_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_dataset = CACD(\"train\",transforms, label_transforms)\n",
    "    test_dataset = CACD(\"test\", transforms, label_transforms)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    model=CGANs(lr=learning_rate)\n",
    "    d_optim=model.d_optim\n",
    "    g_optim=model.g_optim\n",
    "\n",
    "    for epoch in range(max_epoches):\n",
    "        epochp = \"epoch: \" + str(epoch)\n",
    "        print(epochp)\n",
    "        for idx, (source_img_227,source_img_128,true_label_img,true_label_128,true_label_64,fake_label_64, true_label) in enumerate(train_loader,1):\n",
    "\n",
    "            running_d_loss=None\n",
    "            running_g_loss=None\n",
    "            n_iter = epoch * len(train_loader) + idx\n",
    "\n",
    "\n",
    "            #mv to gpu\n",
    "            source_img_227=source_img_227.cuda()\n",
    "            source_img_128=source_img_128.cuda()\n",
    "            true_label_img=true_label_img.cuda()\n",
    "            true_label_128=true_label_128.cuda()\n",
    "            true_label_64=true_label_64.cuda()\n",
    "            fake_label_64=fake_label_64.cuda()\n",
    "            true_label=true_label.cuda()\n",
    "\n",
    "            #train discriminator\n",
    "            for d_iter in range(d_iters):\n",
    "                #d_lr_scheduler.step()\n",
    "                d_optim.zero_grad()\n",
    "                model.train(\n",
    "                    source_img_227=source_img_227,\n",
    "                    source_img_128=source_img_128,\n",
    "                    true_label_img=true_label_img,\n",
    "                    true_label_128=true_label_128,\n",
    "                    true_label_64=true_label_64,\n",
    "                    fake_label_64=fake_label_64,\n",
    "                    age_label=true_label\n",
    "                )\n",
    "                d_loss=model.d_loss\n",
    "                running_d_loss=d_loss\n",
    "                d_loss.backward()\n",
    "                d_optim.step()\n",
    "\n",
    "            #train generator\n",
    "            for g_iter in range(g_iters):\n",
    "                #g_lr_scheduler.step()\n",
    "                g_optim.zero_grad()\n",
    "                model.train(\n",
    "                    source_img_227=source_img_227,\n",
    "                    source_img_128=source_img_128,\n",
    "                    true_label_img=true_label_img,\n",
    "                    true_label_128=true_label_128,\n",
    "                    true_label_64=true_label_64,\n",
    "                    fake_label_64=fake_label_64,\n",
    "                    age_label=true_label\n",
    "                )\n",
    "                g_loss = model.g_loss\n",
    "                running_g_loss=g_loss\n",
    "                g_loss.backward()\n",
    "                g_optim.step()\n",
    "            if idx % 100 == 0:\n",
    "                print('step %d/%d, g_loss = %.3f, d_loss = %.3f' %(idx, len(train_loader),running_g_loss,running_d_loss))\n",
    "\n",
    "            # save the parameters at the end of each save interval\n",
    "            if idx % save_interval == 0:\n",
    "                model.save_model(dir=saved_model_folder,\n",
    "                                 filename='epoch_%d_iter_%d.pth'%(epoch, idx))\n",
    "                print('checkpoint has been created!')\n",
    "\n",
    "            #val step\n",
    "            if idx % val_interval == 0:\n",
    "                save_dir = os.path.join(saved_validation_folder, \"epoch_%d\" % epoch, \"idx_%d\" % idx)\n",
    "                check_dir(save_dir)\n",
    "                for val_idx, (source_img_128, true_label_128) in enumerate(tqdm(test_loader)):\n",
    "                    save_image(Reverse_zero_center()(source_img_128),os.path.join(save_dir,\"batch_%d_source.jpg\"%(val_idx)))\n",
    "\n",
    "                    pic_list = []\n",
    "                    pic_list.append(source_img_128)\n",
    "                    for age in range(age_groups):\n",
    "                        img = model.test_generate(source_img_128, true_label_128[age])\n",
    "                        save_image(Reverse_zero_center()(img),os.path.join(save_dir,\"batch_%d_age_group_%d.jpg\"%(val_idx,age)))\n",
    "                print('validation image has been created!')\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6196783,
     "sourceId": 10247544,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31840.147922,
   "end_time": "2025-01-03T01:30:40.149333",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-02T16:40:00.001411",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
