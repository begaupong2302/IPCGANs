{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10247544,"sourceType":"datasetVersion","datasetId":6196783}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch.utils.data as data\nfrom PIL import Image\nimport os\nimport numpy as np\nimport torchvision\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-20T08:54:38.624268Z","iopub.execute_input":"2024-12-20T08:54:38.624566Z","iopub.status.idle":"2024-12-20T08:54:42.679296Z","shell.execute_reply.started":"2024-12-20T08:54:38.624530Z","shell.execute_reply":"2024-12-20T08:54:42.678296Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\n\ndef check_dir(dir):\n    if not os.path.exists(dir):\n        os.makedirs(dir)\n\nclass Img_to_zero_center(object):\n    def __int__(self):\n        pass\n    def __call__(self, t_img):\n        '''\n        :param img:tensor be 0-1\n        :return:\n        '''\n        t_img=(t_img-0.5)*2\n        return t_img\n\nclass Reverse_zero_center(object):\n    def __init__(self):\n        pass\n    def __call__(self,t_img):\n        t_img=t_img/2+0.5\n        return t_img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T08:54:42.680176Z","iopub.execute_input":"2024-12-20T08:54:42.680584Z","iopub.status.idle":"2024-12-20T08:54:42.685985Z","shell.execute_reply.started":"2024-12-20T08:54:42.680546Z","shell.execute_reply":"2024-12-20T08:54:42.685167Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class CACD(data.Dataset):\n    def __init__(self, split='train', transforms=None, label_transforms=None):\n        list_root = \"/kaggle/input/utkpreprocess/lists\"\n        data_root = \"/kaggle/input/utkpreprocess/UTKFaceCrop\"\n        if split == \"train\":\n            self.list_path=os.path.join(list_root,\"train.txt\")\n        else:\n            self.list_path = os.path.join(list_root, \"test.txt\")\n        self.images_labels=[]#path\n        self.transform=transforms\n        self.label_transform=label_transforms\n        with open(self.list_path) as fr:\n            lines=fr.readlines()\n            for line in lines:\n                line.strip()\n                item=line.split()\n                image_label=[]\n                image_label.append(os.path.join(data_root,item[0]))\n                try:\n                    image_label.append(np.array(int(item[1])))\n                except:\n                  print(item[0])\n                  print(item[1])\n                self.images_labels.append(image_label)\n\n    def __getitem__(self, idx):\n        img_path,label=self.images_labels[idx]\n        img=Image.open(img_path)\n\n        if self.transform is not None:\n            img=self.transform(img)\n        if self.label_transform is None:\n            label=torch.from_numpy(label)\n        return img,label\n\n    def __len__(self):\n        return len(self.images_labels)\n\n\ntransforms = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[1., 1., 1.]),\n])\n\nCACD_dataset=CACD(\"train\", transforms, None)\ntrain_loader = torch.utils.data.DataLoader(\n    dataset=CACD_dataset,\n    batch_size=32,\n    shuffle=False\n)\nfor idx,(img,label) in enumerate(train_loader):\n    print(img.size())\n    print(label.size())\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T08:54:42.686735Z","iopub.execute_input":"2024-12-20T08:54:42.687020Z","iopub.status.idle":"2024-12-20T08:54:43.132301Z","shell.execute_reply.started":"2024-12-20T08:54:42.686993Z","shell.execute_reply":"2024-12-20T08:54:43.131401Z"}},"outputs":[{"name":"stdout","text":"torch.Size([32, 3, 400, 400])\ntorch.Size([32])\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import math\nfrom torch.nn.parameter import Parameter\nfrom torch.nn.functional import pad\nfrom torch.nn.modules import Module\nfrom torch.nn.modules.utils import _single, _pair, _triple\n\nclass _ConvNd(Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride,\n                 padding, dilation, transposed, output_padding, groups, bias):\n        super(_ConvNd, self).__init__()\n        if in_channels % groups != 0:\n            raise ValueError('in_channels must be divisible by groups')\n        if out_channels % groups != 0:\n            raise ValueError('out_channels must be divisible by groups')\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n        self.transposed = transposed\n        self.output_padding = output_padding\n        self.groups = groups\n        if transposed:\n            self.weight = Parameter(torch.Tensor(\n                in_channels, out_channels // groups, *kernel_size))\n        else:\n            self.weight = Parameter(torch.Tensor(\n                out_channels, in_channels // groups, *kernel_size))\n        if bias:\n            self.bias = Parameter(torch.Tensor(out_channels))\n        else:\n            self.register_parameter('bias', None)\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        n = self.in_channels\n        for k in self.kernel_size:\n            n *= k\n        stdv = 1. / math.sqrt(n)\n        self.weight.data.uniform_(-stdv, stdv)\n        if self.bias is not None:\n            self.bias.data.uniform_(-stdv, stdv)\n\n    def __repr__(self):\n        s = ('{name}({in_channels}, {out_channels}, kernel_size={kernel_size}'\n             ', stride={stride}')\n        if self.padding != (0,) * len(self.padding):\n            s += ', padding={padding}'\n        if self.dilation != (1,) * len(self.dilation):\n            s += ', dilation={dilation}'\n        if self.output_padding != (0,) * len(self.output_padding):\n            s += ', output_padding={output_padding}'\n        if self.groups != 1:\n            s += ', groups={groups}'\n        if self.bias is None:\n            s += ', bias=False'\n        s += ')'\n        return s.format(name=self.__class__.__name__, **self.__dict__)\n\nclass Conv2d(_ConvNd):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n                 padding=0, dilation=1, groups=1, bias=True):\n        kernel_size = _pair(kernel_size)\n        stride = _pair(stride)\n        padding = _pair(padding)\n        dilation = _pair(dilation)\n        super(Conv2d, self).__init__(\n            in_channels, out_channels, kernel_size, stride, padding, dilation,\n            False, _pair(0), groups, bias)\n\n    def forward(self, input):\n        return _conv2d_same_padding(input, self.weight, self.bias, self.stride,\n                        self.padding, self.dilation, self.groups)\n\n# custom conv2d, because pytorch don't have \"padding='same'\" option.\ndef _conv2d_same_padding(input, weight, bias=None, stride=(1,1), padding=1, dilation=(1,1), groups=1):\n\n    input_rows = input.size(2)\n    filter_rows = weight.size(2)\n    effective_filter_size_rows = (filter_rows - 1) * dilation[0] + 1\n    out_rows = (input_rows + stride[0] - 1) // stride[0]\n    padding_needed = max(0, (out_rows - 1) * stride[0] + effective_filter_size_rows -\n                  input_rows)\n    padding_rows = max(0, (out_rows - 1) * stride[0] +\n                        (filter_rows - 1) * dilation[0] + 1 - input_rows)\n    rows_odd = (padding_rows % 2 != 0)\n    padding_cols = max(0, (out_rows - 1) * stride[0] +\n                        (filter_rows - 1) * dilation[0] + 1 - input_rows)\n    cols_odd = (padding_rows % 2 != 0)\n\n    if rows_odd or cols_odd:\n        input = pad(input, [0, int(cols_odd), 0, int(rows_odd)])\n\n    return F.conv2d(input, weight, bias, stride,\n                  padding=(padding_rows // 2, padding_cols // 2),\n                  dilation=dilation, groups=groups)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T08:54:43.133273Z","iopub.execute_input":"2024-12-20T08:54:43.133592Z","iopub.status.idle":"2024-12-20T08:54:43.146541Z","shell.execute_reply.started":"2024-12-20T08:54:43.133561Z","shell.execute_reply":"2024-12-20T08:54:43.145647Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class AgeAlexNet(nn.Module):\n    def __init__(self,pretrainded=False,modelpath=None):\n        super(AgeAlexNet, self).__init__()\n        assert pretrainded is False or modelpath is not None,\"pretrain model need to be specified\"\n        self.features = nn.Sequential(\n            Conv2d(3, 96, kernel_size=11, stride=4),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.LocalResponseNorm(2,2e-5,0.75),\n\n            Conv2d(96, 256, kernel_size=5, stride=1,groups=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.LocalResponseNorm(2, 2e-5, 0.75),\n\n            Conv2d(256, 384, kernel_size=3, stride=1),\n            nn.ReLU(inplace=True),\n\n            Conv2d(384, 384, kernel_size=3,stride=1,groups=2),\n            nn.ReLU(inplace=True),\n\n            Conv2d(384, 256, kernel_size=3,stride=1,groups=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.age_classifier=nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, 5),\n        )\n        if pretrainded is True:\n            self.load_pretrained_params(modelpath)\n\n        self.Conv3_feature_module=nn.Sequential()\n        self.Conv4_feature_module=nn.Sequential()\n        self.Conv5_feature_module=nn.Sequential()\n        self.Pool5_feature_module=nn.Sequential()\n        for x in range(10):\n            self.Conv3_feature_module.add_module(str(x), self.features[x])\n        for x in range(10,12):\n            self.Conv4_feature_module.add_module(str(x),self.features[x])\n        for x in range(12,14):\n            self.Conv5_feature_module.add_module(str(x),self.features[x])\n        for x in range(14,15):\n            self.Pool5_feature_module.add_module(str(x),self.features[x])\n\n\n    def forward(self, x):\n        self.conv3_feature=self.Conv3_feature_module(x)\n        self.conv4_feature=self.Conv4_feature_module(self.conv3_feature)\n        self.conv5_feature=self.Conv5_feature_module(self.conv4_feature)\n        pool5_feature=self.Pool5_feature_module(self.conv5_feature)\n        self.pool5_feature=pool5_feature\n        flattened = pool5_feature.view(pool5_feature.size(0), -1)\n        age_logit = self.age_classifier(flattened)\n        return age_logit\n\n    def load_pretrained_params(self,path):\n        # step1: load pretrained model\n        pretrained_dict = torch.load(path)\n        # step2: get model state_dict\n        model_dict = self.state_dict()\n        # step3: remove pretrained_dict params which is not in model_dict\n        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n        # step4: update model_dict using pretrained_dict\n        model_dict.update(pretrained_dict)\n        # step5: update model using model_dict\n        self.load_state_dict(model_dict)\n\n\nclass AgeClassify:\n    def __init__(self, modelz = AgeAlexNet(pretrainded=False).cuda()):\n        #step 1:define model\n        self.model=modelz\n        #step 2:define optimizer\n        self.optim=torch.optim.Adam(self.model.parameters(),lr=1e-4,betas=(0.5, 0.999))\n        #step 3:define loss\n        self.criterion=nn.CrossEntropyLoss().cuda()\n\n    def train(self,input,label):\n        self.model.train()\n        output=self.model(input)\n        self.loss=self.criterion(output,label)\n\n    def val(self,input):\n        self.model.eval()\n        output=F.softmax(self.model(input),dim=1).max(1)[1]\n        return output\n\n    def save_model(self,dir,filename):\n        torch.save(self.model.state_dict(),os.path.join(dir,filename))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T09:42:26.617797Z","iopub.execute_input":"2024-12-20T09:42:26.618134Z","iopub.status.idle":"2024-12-20T09:42:27.014645Z","shell.execute_reply.started":"2024-12-20T09:42:26.618086Z","shell.execute_reply":"2024-12-20T09:42:27.013954Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"batch_size 512 20 epochs","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport os\n\n#define\nmax_epoches = 20\nbatch_size = 512\nsave_interval = 20000\nval_interval = 20000\nsaved_model_folder = '/kaggle/working/checkpoint'\ncheck_dir(saved_model_folder)\n\ntransforms = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((227, 227)),\n    torchvision.transforms.ToTensor(),\n    Img_to_zero_center()\n])\n\ntrain_dataset = CACD(\"train\", transforms, None)\ntest_dataset = CACD(\"test\", transforms, None)\ntrain_loader = torch.utils.data.DataLoader(\n    dataset=train_dataset,\n    batch_size=batch_size,\n    shuffle=True\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    dataset=test_dataset,\n    batch_size=batch_size,\n    shuffle=True\n)\n\nmodel=AgeClassify()\noptim=model.optim\n\nfor epoch in range(max_epoches):\n    for train_idx, (img,label) in enumerate(train_loader):\n        img=img.cuda()\n        label=label.cuda()\n\n        #train\n        optim.zero_grad()\n        model.train(img,label)\n        loss=model.loss\n        loss.backward()\n        optim.step()\n\n        print('step %d/%d, cls_loss = %.3f' % (train_idx, len(train_loader), loss))\n\n        # save the parameters at the end of each save interval\n        if train_idx*batch_size % save_interval == 0:\n            model.save_model(dir=saved_model_folder,\n                              filename='epoch_%d_iter_%d.pth'%(epoch, train_idx))\n            print('checkpoint has been created!')\n\n        #val step\n\n        if train_idx % val_interval == 0:\n            train_correct=0\n            train_total=0\n            with torch.no_grad():\n                for val_img,val_label in tqdm(test_loader):\n                    val_img=val_img.cuda()\n                    val_label=val_label.cuda()\n                    output=model.val(val_img)\n                    train_correct += (output == val_label).sum()\n                    train_total += val_img.size()[0]\n\n            print('validate has been finished!')\n            print('val_acc = %.3f' % (train_correct.cpu().numpy()/train_total))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T08:54:43.165166Z","iopub.execute_input":"2024-12-20T08:54:43.165458Z","iopub.status.idle":"2024-12-20T09:38:57.810549Z","shell.execute_reply.started":"2024-12-20T08:54:43.165436Z","shell.execute_reply":"2024-12-20T09:38:57.809249Z"}},"outputs":[{"name":"stdout","text":"step 0/41, cls_loss = 1.612\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:17<00:00,  3.59s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.330\nstep 1/41, cls_loss = 1.604\nstep 2/41, cls_loss = 1.586\nstep 3/41, cls_loss = 1.578\nstep 4/41, cls_loss = 1.547\nstep 5/41, cls_loss = 1.554\nstep 6/41, cls_loss = 1.522\nstep 7/41, cls_loss = 1.564\nstep 8/41, cls_loss = 1.543\nstep 9/41, cls_loss = 1.524\nstep 10/41, cls_loss = 1.522\nstep 11/41, cls_loss = 1.501\nstep 12/41, cls_loss = 1.527\nstep 13/41, cls_loss = 1.537\nstep 14/41, cls_loss = 1.540\nstep 15/41, cls_loss = 1.486\nstep 16/41, cls_loss = 1.503\nstep 17/41, cls_loss = 1.537\nstep 18/41, cls_loss = 1.531\nstep 19/41, cls_loss = 1.530\nstep 20/41, cls_loss = 1.476\nstep 21/41, cls_loss = 1.542\nstep 22/41, cls_loss = 1.455\nstep 23/41, cls_loss = 1.524\nstep 24/41, cls_loss = 1.495\nstep 25/41, cls_loss = 1.505\nstep 26/41, cls_loss = 1.488\nstep 27/41, cls_loss = 1.507\nstep 28/41, cls_loss = 1.480\nstep 29/41, cls_loss = 1.471\nstep 30/41, cls_loss = 1.485\nstep 31/41, cls_loss = 1.500\nstep 32/41, cls_loss = 1.479\nstep 33/41, cls_loss = 1.449\nstep 34/41, cls_loss = 1.443\nstep 35/41, cls_loss = 1.469\nstep 36/41, cls_loss = 1.438\nstep 37/41, cls_loss = 1.482\nstep 38/41, cls_loss = 1.455\nstep 39/41, cls_loss = 1.484\nstep 40/41, cls_loss = 1.423\nstep 0/41, cls_loss = 1.495\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:10<00:00,  2.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.357\nstep 1/41, cls_loss = 1.493\nstep 2/41, cls_loss = 1.452\nstep 3/41, cls_loss = 1.397\nstep 4/41, cls_loss = 1.456\nstep 5/41, cls_loss = 1.526\nstep 6/41, cls_loss = 1.406\nstep 7/41, cls_loss = 1.468\nstep 8/41, cls_loss = 1.433\nstep 9/41, cls_loss = 1.402\nstep 10/41, cls_loss = 1.370\nstep 11/41, cls_loss = 1.421\nstep 12/41, cls_loss = 1.541\nstep 13/41, cls_loss = 1.485\nstep 14/41, cls_loss = 1.407\nstep 15/41, cls_loss = 1.521\nstep 16/41, cls_loss = 1.445\nstep 17/41, cls_loss = 1.419\nstep 18/41, cls_loss = 1.359\nstep 19/41, cls_loss = 1.434\nstep 20/41, cls_loss = 1.460\nstep 21/41, cls_loss = 1.418\nstep 22/41, cls_loss = 1.329\nstep 23/41, cls_loss = 1.341\nstep 24/41, cls_loss = 1.361\nstep 25/41, cls_loss = 1.389\nstep 26/41, cls_loss = 1.355\nstep 27/41, cls_loss = 1.295\nstep 28/41, cls_loss = 1.294\nstep 29/41, cls_loss = 1.295\nstep 30/41, cls_loss = 1.249\nstep 31/41, cls_loss = 1.318\nstep 32/41, cls_loss = 1.304\nstep 33/41, cls_loss = 1.292\nstep 34/41, cls_loss = 1.397\nstep 35/41, cls_loss = 1.317\nstep 36/41, cls_loss = 1.312\nstep 37/41, cls_loss = 1.295\nstep 38/41, cls_loss = 1.373\nstep 39/41, cls_loss = 1.362\nstep 40/41, cls_loss = 1.340\nstep 0/41, cls_loss = 1.313\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:09<00:00,  1.96s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.493\nstep 1/41, cls_loss = 1.250\nstep 2/41, cls_loss = 1.295\nstep 3/41, cls_loss = 1.379\nstep 4/41, cls_loss = 1.375\nstep 5/41, cls_loss = 1.389\nstep 6/41, cls_loss = 1.296\nstep 7/41, cls_loss = 1.358\nstep 8/41, cls_loss = 1.318\nstep 9/41, cls_loss = 1.300\nstep 10/41, cls_loss = 1.241\nstep 11/41, cls_loss = 1.242\nstep 12/41, cls_loss = 1.280\nstep 13/41, cls_loss = 1.241\nstep 14/41, cls_loss = 1.280\nstep 15/41, cls_loss = 1.178\nstep 16/41, cls_loss = 1.253\nstep 17/41, cls_loss = 1.309\nstep 18/41, cls_loss = 1.403\nstep 19/41, cls_loss = 1.293\nstep 20/41, cls_loss = 1.343\nstep 21/41, cls_loss = 1.315\nstep 22/41, cls_loss = 1.195\nstep 23/41, cls_loss = 1.275\nstep 24/41, cls_loss = 1.217\nstep 25/41, cls_loss = 1.189\nstep 26/41, cls_loss = 1.224\nstep 27/41, cls_loss = 1.326\nstep 28/41, cls_loss = 1.378\nstep 29/41, cls_loss = 1.315\nstep 30/41, cls_loss = 1.263\nstep 31/41, cls_loss = 1.202\nstep 32/41, cls_loss = 1.149\nstep 33/41, cls_loss = 1.234\nstep 34/41, cls_loss = 1.192\nstep 35/41, cls_loss = 1.224\nstep 36/41, cls_loss = 1.178\nstep 37/41, cls_loss = 1.196\nstep 38/41, cls_loss = 1.109\nstep 39/41, cls_loss = 1.146\nstep 40/41, cls_loss = 1.222\nstep 0/41, cls_loss = 1.291\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:10<00:00,  2.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.526\nstep 1/41, cls_loss = 1.225\nstep 2/41, cls_loss = 1.191\nstep 3/41, cls_loss = 1.155\nstep 4/41, cls_loss = 1.186\nstep 5/41, cls_loss = 1.227\nstep 6/41, cls_loss = 1.183\nstep 7/41, cls_loss = 1.155\nstep 8/41, cls_loss = 1.206\nstep 9/41, cls_loss = 1.143\nstep 10/41, cls_loss = 1.262\nstep 11/41, cls_loss = 1.309\nstep 12/41, cls_loss = 1.221\nstep 13/41, cls_loss = 1.217\nstep 14/41, cls_loss = 1.170\nstep 15/41, cls_loss = 1.118\nstep 16/41, cls_loss = 1.129\nstep 17/41, cls_loss = 1.158\nstep 18/41, cls_loss = 1.044\nstep 19/41, cls_loss = 1.130\nstep 20/41, cls_loss = 1.140\nstep 21/41, cls_loss = 1.178\nstep 22/41, cls_loss = 1.225\nstep 23/41, cls_loss = 1.219\nstep 24/41, cls_loss = 1.235\nstep 25/41, cls_loss = 1.176\nstep 26/41, cls_loss = 1.096\nstep 27/41, cls_loss = 1.169\nstep 28/41, cls_loss = 1.170\nstep 29/41, cls_loss = 1.171\nstep 30/41, cls_loss = 1.116\nstep 31/41, cls_loss = 1.101\nstep 32/41, cls_loss = 1.091\nstep 33/41, cls_loss = 1.118\nstep 34/41, cls_loss = 1.015\nstep 35/41, cls_loss = 1.125\nstep 36/41, cls_loss = 1.105\nstep 37/41, cls_loss = 1.158\nstep 38/41, cls_loss = 1.054\nstep 39/41, cls_loss = 1.079\nstep 40/41, cls_loss = 1.230\nstep 0/41, cls_loss = 1.110\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:10<00:00,  2.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.516\nstep 1/41, cls_loss = 1.179\nstep 2/41, cls_loss = 1.300\nstep 3/41, cls_loss = 1.171\nstep 4/41, cls_loss = 1.062\nstep 5/41, cls_loss = 1.045\nstep 6/41, cls_loss = 1.038\nstep 7/41, cls_loss = 1.101\nstep 8/41, cls_loss = 1.060\nstep 9/41, cls_loss = 1.102\nstep 10/41, cls_loss = 1.086\nstep 11/41, cls_loss = 1.063\nstep 12/41, cls_loss = 1.128\nstep 13/41, cls_loss = 1.127\nstep 14/41, cls_loss = 1.097\nstep 15/41, cls_loss = 1.131\nstep 16/41, cls_loss = 1.067\nstep 17/41, cls_loss = 1.119\nstep 18/41, cls_loss = 1.094\nstep 19/41, cls_loss = 1.157\nstep 20/41, cls_loss = 1.100\nstep 21/41, cls_loss = 1.034\nstep 22/41, cls_loss = 1.055\nstep 23/41, cls_loss = 1.041\nstep 24/41, cls_loss = 1.037\nstep 25/41, cls_loss = 1.036\nstep 26/41, cls_loss = 1.007\nstep 27/41, cls_loss = 1.085\nstep 28/41, cls_loss = 1.031\nstep 29/41, cls_loss = 1.070\nstep 30/41, cls_loss = 0.921\nstep 31/41, cls_loss = 1.038\nstep 32/41, cls_loss = 1.014\nstep 33/41, cls_loss = 1.195\nstep 34/41, cls_loss = 1.442\nstep 35/41, cls_loss = 1.280\nstep 36/41, cls_loss = 1.252\nstep 37/41, cls_loss = 1.108\nstep 38/41, cls_loss = 1.075\nstep 39/41, cls_loss = 1.042\nstep 40/41, cls_loss = 0.960\nstep 0/41, cls_loss = 1.075\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:09<00:00,  1.95s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.570\nstep 1/41, cls_loss = 1.149\nstep 2/41, cls_loss = 1.085\nstep 3/41, cls_loss = 1.119\nstep 4/41, cls_loss = 1.037\nstep 5/41, cls_loss = 1.063\nstep 6/41, cls_loss = 1.019\nstep 7/41, cls_loss = 1.016\nstep 8/41, cls_loss = 1.034\nstep 9/41, cls_loss = 1.068\nstep 10/41, cls_loss = 1.011\nstep 11/41, cls_loss = 1.040\nstep 12/41, cls_loss = 0.957\nstep 13/41, cls_loss = 1.018\nstep 14/41, cls_loss = 0.948\nstep 15/41, cls_loss = 0.931\nstep 16/41, cls_loss = 0.961\nstep 17/41, cls_loss = 1.052\nstep 18/41, cls_loss = 0.985\nstep 19/41, cls_loss = 0.957\nstep 20/41, cls_loss = 1.066\nstep 21/41, cls_loss = 1.022\nstep 22/41, cls_loss = 1.016\nstep 23/41, cls_loss = 1.046\nstep 24/41, cls_loss = 1.090\nstep 25/41, cls_loss = 1.004\nstep 26/41, cls_loss = 1.011\nstep 27/41, cls_loss = 0.990\nstep 28/41, cls_loss = 1.077\nstep 29/41, cls_loss = 1.045\nstep 30/41, cls_loss = 0.990\nstep 31/41, cls_loss = 1.037\nstep 32/41, cls_loss = 0.997\nstep 33/41, cls_loss = 1.037\nstep 34/41, cls_loss = 0.958\nstep 35/41, cls_loss = 1.031\nstep 36/41, cls_loss = 0.993\nstep 37/41, cls_loss = 0.996\nstep 38/41, cls_loss = 0.955\nstep 39/41, cls_loss = 1.090\nstep 40/41, cls_loss = 1.093\nstep 0/41, cls_loss = 1.013\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:09<00:00,  1.97s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.584\nstep 1/41, cls_loss = 1.028\nstep 2/41, cls_loss = 0.998\nstep 3/41, cls_loss = 0.972\nstep 4/41, cls_loss = 1.034\nstep 5/41, cls_loss = 1.013\nstep 6/41, cls_loss = 0.993\nstep 7/41, cls_loss = 0.983\nstep 8/41, cls_loss = 0.916\nstep 9/41, cls_loss = 1.040\nstep 10/41, cls_loss = 0.930\nstep 11/41, cls_loss = 0.969\nstep 12/41, cls_loss = 1.014\nstep 13/41, cls_loss = 0.935\nstep 14/41, cls_loss = 1.027\nstep 15/41, cls_loss = 1.012\nstep 16/41, cls_loss = 0.982\nstep 17/41, cls_loss = 1.046\nstep 18/41, cls_loss = 0.948\nstep 19/41, cls_loss = 0.976\nstep 20/41, cls_loss = 0.990\nstep 21/41, cls_loss = 0.941\nstep 22/41, cls_loss = 0.986\nstep 23/41, cls_loss = 0.980\nstep 24/41, cls_loss = 1.094\nstep 25/41, cls_loss = 1.123\nstep 26/41, cls_loss = 1.059\nstep 27/41, cls_loss = 0.994\nstep 28/41, cls_loss = 0.991\nstep 29/41, cls_loss = 0.997\nstep 30/41, cls_loss = 0.936\nstep 31/41, cls_loss = 1.039\nstep 32/41, cls_loss = 0.966\nstep 33/41, cls_loss = 0.891\nstep 34/41, cls_loss = 0.964\nstep 35/41, cls_loss = 1.008\nstep 36/41, cls_loss = 1.011\nstep 37/41, cls_loss = 0.918\nstep 38/41, cls_loss = 0.975\nstep 39/41, cls_loss = 0.920\nstep 40/41, cls_loss = 0.924\nstep 0/41, cls_loss = 0.950\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:09<00:00,  1.97s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.621\nstep 1/41, cls_loss = 0.900\nstep 2/41, cls_loss = 0.917\nstep 3/41, cls_loss = 0.968\nstep 4/41, cls_loss = 0.930\nstep 5/41, cls_loss = 0.920\nstep 6/41, cls_loss = 0.943\nstep 7/41, cls_loss = 1.048\nstep 8/41, cls_loss = 1.022\nstep 9/41, cls_loss = 0.951\nstep 10/41, cls_loss = 0.933\nstep 11/41, cls_loss = 0.906\nstep 12/41, cls_loss = 0.973\nstep 13/41, cls_loss = 0.926\nstep 14/41, cls_loss = 0.944\nstep 15/41, cls_loss = 0.914\nstep 16/41, cls_loss = 0.949\nstep 17/41, cls_loss = 0.935\nstep 18/41, cls_loss = 0.948\nstep 19/41, cls_loss = 0.938\nstep 20/41, cls_loss = 0.907\nstep 21/41, cls_loss = 0.857\nstep 22/41, cls_loss = 0.887\nstep 23/41, cls_loss = 0.998\nstep 24/41, cls_loss = 1.057\nstep 25/41, cls_loss = 1.053\nstep 26/41, cls_loss = 1.003\nstep 27/41, cls_loss = 0.938\nstep 28/41, cls_loss = 0.915\nstep 29/41, cls_loss = 0.931\nstep 30/41, cls_loss = 0.902\nstep 31/41, cls_loss = 0.924\nstep 32/41, cls_loss = 0.959\nstep 33/41, cls_loss = 0.856\nstep 34/41, cls_loss = 0.881\nstep 35/41, cls_loss = 0.912\nstep 36/41, cls_loss = 0.867\nstep 37/41, cls_loss = 0.951\nstep 38/41, cls_loss = 1.141\nstep 39/41, cls_loss = 1.011\nstep 40/41, cls_loss = 0.982\nstep 0/41, cls_loss = 0.923\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:09<00:00,  1.98s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.626\nstep 1/41, cls_loss = 0.870\nstep 2/41, cls_loss = 0.941\nstep 3/41, cls_loss = 0.908\nstep 4/41, cls_loss = 0.924\nstep 5/41, cls_loss = 0.923\nstep 6/41, cls_loss = 0.913\nstep 7/41, cls_loss = 0.886\nstep 8/41, cls_loss = 0.937\nstep 9/41, cls_loss = 0.843\nstep 10/41, cls_loss = 0.916\nstep 11/41, cls_loss = 1.006\nstep 12/41, cls_loss = 0.929\nstep 13/41, cls_loss = 0.935\nstep 14/41, cls_loss = 0.915\nstep 15/41, cls_loss = 1.009\nstep 16/41, cls_loss = 0.904\nstep 17/41, cls_loss = 0.944\nstep 18/41, cls_loss = 0.857\nstep 19/41, cls_loss = 0.976\nstep 20/41, cls_loss = 0.889\nstep 21/41, cls_loss = 0.855\nstep 22/41, cls_loss = 0.943\nstep 23/41, cls_loss = 0.898\nstep 24/41, cls_loss = 0.888\nstep 25/41, cls_loss = 0.871\nstep 26/41, cls_loss = 0.842\nstep 27/41, cls_loss = 0.830\nstep 28/41, cls_loss = 0.954\nstep 29/41, cls_loss = 0.867\nstep 30/41, cls_loss = 0.990\nstep 31/41, cls_loss = 0.985\nstep 32/41, cls_loss = 0.901\nstep 33/41, cls_loss = 0.914\nstep 34/41, cls_loss = 0.828\nstep 35/41, cls_loss = 0.842\nstep 36/41, cls_loss = 0.885\nstep 37/41, cls_loss = 1.033\nstep 38/41, cls_loss = 1.007\nstep 39/41, cls_loss = 0.914\nstep 40/41, cls_loss = 0.915\nstep 0/41, cls_loss = 0.929\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:10<00:00,  2.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.624\nstep 1/41, cls_loss = 0.916\nstep 2/41, cls_loss = 0.822\nstep 3/41, cls_loss = 0.840\nstep 4/41, cls_loss = 0.865\nstep 5/41, cls_loss = 0.850\nstep 6/41, cls_loss = 0.928\nstep 7/41, cls_loss = 0.876\nstep 8/41, cls_loss = 0.832\nstep 9/41, cls_loss = 0.856\nstep 10/41, cls_loss = 0.849\nstep 11/41, cls_loss = 0.823\nstep 12/41, cls_loss = 0.811\nstep 13/41, cls_loss = 0.833\nstep 14/41, cls_loss = 0.899\nstep 15/41, cls_loss = 0.826\nstep 16/41, cls_loss = 0.894\nstep 17/41, cls_loss = 0.822\nstep 18/41, cls_loss = 0.899\nstep 19/41, cls_loss = 0.973\nstep 20/41, cls_loss = 0.962\nstep 21/41, cls_loss = 0.895\nstep 22/41, cls_loss = 0.826\nstep 23/41, cls_loss = 0.942\nstep 24/41, cls_loss = 0.876\nstep 25/41, cls_loss = 0.834\nstep 26/41, cls_loss = 0.870\nstep 27/41, cls_loss = 0.913\nstep 28/41, cls_loss = 0.863\nstep 29/41, cls_loss = 0.821\nstep 30/41, cls_loss = 0.802\nstep 31/41, cls_loss = 0.842\nstep 32/41, cls_loss = 0.815\nstep 33/41, cls_loss = 0.764\nstep 34/41, cls_loss = 0.833\nstep 35/41, cls_loss = 0.857\nstep 36/41, cls_loss = 0.890\nstep 37/41, cls_loss = 0.833\nstep 38/41, cls_loss = 0.920\nstep 39/41, cls_loss = 0.883\nstep 40/41, cls_loss = 0.987\nstep 0/41, cls_loss = 1.160\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:09<00:00,  1.98s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.572\nstep 1/41, cls_loss = 0.976\nstep 2/41, cls_loss = 0.957\nstep 3/41, cls_loss = 0.896\nstep 4/41, cls_loss = 0.830\nstep 5/41, cls_loss = 0.838\nstep 6/41, cls_loss = 0.878\nstep 7/41, cls_loss = 0.876\nstep 8/41, cls_loss = 0.820\nstep 9/41, cls_loss = 0.855\nstep 10/41, cls_loss = 0.862\nstep 11/41, cls_loss = 0.832\nstep 12/41, cls_loss = 0.838\nstep 13/41, cls_loss = 0.915\nstep 14/41, cls_loss = 0.890\nstep 15/41, cls_loss = 0.953\nstep 16/41, cls_loss = 0.886\nstep 17/41, cls_loss = 0.819\nstep 18/41, cls_loss = 0.878\nstep 19/41, cls_loss = 0.836\nstep 20/41, cls_loss = 0.793\nstep 21/41, cls_loss = 0.899\nstep 22/41, cls_loss = 0.784\nstep 23/41, cls_loss = 0.785\nstep 24/41, cls_loss = 0.864\nstep 25/41, cls_loss = 0.823\nstep 26/41, cls_loss = 0.853\nstep 27/41, cls_loss = 0.851\nstep 28/41, cls_loss = 0.844\nstep 29/41, cls_loss = 0.837\nstep 30/41, cls_loss = 0.889\nstep 31/41, cls_loss = 0.791\nstep 32/41, cls_loss = 0.911\nstep 33/41, cls_loss = 0.849\nstep 34/41, cls_loss = 0.873\nstep 35/41, cls_loss = 0.798\nstep 36/41, cls_loss = 0.903\nstep 37/41, cls_loss = 0.840\nstep 38/41, cls_loss = 0.744\nstep 39/41, cls_loss = 0.733\nstep 40/41, cls_loss = 0.949\nstep 0/41, cls_loss = 0.964\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:09<00:00,  1.97s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.628\nstep 1/41, cls_loss = 0.858\nstep 2/41, cls_loss = 0.864\nstep 3/41, cls_loss = 0.802\nstep 4/41, cls_loss = 0.790\nstep 5/41, cls_loss = 0.790\nstep 6/41, cls_loss = 0.716\nstep 7/41, cls_loss = 0.805\nstep 8/41, cls_loss = 0.785\nstep 9/41, cls_loss = 0.766\nstep 10/41, cls_loss = 0.888\nstep 11/41, cls_loss = 0.779\nstep 12/41, cls_loss = 0.785\nstep 13/41, cls_loss = 0.803\nstep 14/41, cls_loss = 0.781\nstep 15/41, cls_loss = 0.809\nstep 16/41, cls_loss = 0.825\nstep 17/41, cls_loss = 0.776\nstep 18/41, cls_loss = 0.812\nstep 19/41, cls_loss = 0.828\nstep 20/41, cls_loss = 0.775\nstep 21/41, cls_loss = 0.828\nstep 22/41, cls_loss = 0.819\nstep 23/41, cls_loss = 0.812\nstep 24/41, cls_loss = 0.856\nstep 25/41, cls_loss = 0.826\nstep 26/41, cls_loss = 0.826\nstep 27/41, cls_loss = 0.826\nstep 28/41, cls_loss = 0.789\nstep 29/41, cls_loss = 0.805\nstep 30/41, cls_loss = 0.794\nstep 31/41, cls_loss = 0.796\nstep 32/41, cls_loss = 0.832\nstep 33/41, cls_loss = 0.857\nstep 34/41, cls_loss = 0.837\nstep 35/41, cls_loss = 0.744\nstep 36/41, cls_loss = 0.794\nstep 37/41, cls_loss = 0.860\nstep 38/41, cls_loss = 0.819\nstep 39/41, cls_loss = 0.838\nstep 40/41, cls_loss = 0.903\nstep 0/41, cls_loss = 0.785\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:10<00:00,  2.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.643\nstep 1/41, cls_loss = 0.801\nstep 2/41, cls_loss = 0.790\nstep 3/41, cls_loss = 0.772\nstep 4/41, cls_loss = 0.750\nstep 5/41, cls_loss = 0.770\nstep 6/41, cls_loss = 0.778\nstep 7/41, cls_loss = 0.722\nstep 8/41, cls_loss = 0.882\nstep 9/41, cls_loss = 0.968\nstep 10/41, cls_loss = 1.028\nstep 11/41, cls_loss = 0.795\nstep 12/41, cls_loss = 0.873\nstep 13/41, cls_loss = 0.823\nstep 14/41, cls_loss = 0.859\nstep 15/41, cls_loss = 0.768\nstep 16/41, cls_loss = 0.828\nstep 17/41, cls_loss = 0.747\nstep 18/41, cls_loss = 0.786\nstep 19/41, cls_loss = 0.786\nstep 20/41, cls_loss = 0.821\nstep 21/41, cls_loss = 0.814\nstep 22/41, cls_loss = 0.896\nstep 23/41, cls_loss = 0.880\nstep 24/41, cls_loss = 0.874\nstep 25/41, cls_loss = 0.819\nstep 26/41, cls_loss = 0.716\nstep 27/41, cls_loss = 0.801\nstep 28/41, cls_loss = 0.753\nstep 29/41, cls_loss = 0.751\nstep 30/41, cls_loss = 0.827\nstep 31/41, cls_loss = 0.841\nstep 32/41, cls_loss = 0.819\nstep 33/41, cls_loss = 0.801\nstep 34/41, cls_loss = 0.770\nstep 35/41, cls_loss = 0.731\nstep 36/41, cls_loss = 0.759\nstep 37/41, cls_loss = 0.741\nstep 38/41, cls_loss = 0.744\nstep 39/41, cls_loss = 0.824\nstep 40/41, cls_loss = 0.797\nstep 0/41, cls_loss = 0.719\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:10<00:00,  2.04s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.652\nstep 1/41, cls_loss = 0.795\nstep 2/41, cls_loss = 0.823\nstep 3/41, cls_loss = 0.823\nstep 4/41, cls_loss = 0.771\nstep 5/41, cls_loss = 0.770\nstep 6/41, cls_loss = 0.758\nstep 7/41, cls_loss = 0.792\nstep 8/41, cls_loss = 0.827\nstep 9/41, cls_loss = 0.814\nstep 10/41, cls_loss = 0.816\nstep 11/41, cls_loss = 0.812\nstep 12/41, cls_loss = 0.805\nstep 13/41, cls_loss = 0.749\nstep 14/41, cls_loss = 0.726\nstep 15/41, cls_loss = 0.784\nstep 16/41, cls_loss = 0.780\nstep 17/41, cls_loss = 0.789\nstep 18/41, cls_loss = 0.797\nstep 19/41, cls_loss = 0.816\nstep 20/41, cls_loss = 0.757\nstep 21/41, cls_loss = 0.758\nstep 22/41, cls_loss = 0.742\nstep 23/41, cls_loss = 0.789\nstep 24/41, cls_loss = 0.709\nstep 25/41, cls_loss = 0.761\nstep 26/41, cls_loss = 0.755\nstep 27/41, cls_loss = 0.848\nstep 28/41, cls_loss = 0.883\nstep 29/41, cls_loss = 0.772\nstep 30/41, cls_loss = 0.779\nstep 31/41, cls_loss = 0.805\nstep 32/41, cls_loss = 0.698\nstep 33/41, cls_loss = 0.785\nstep 34/41, cls_loss = 0.754\nstep 35/41, cls_loss = 0.778\nstep 36/41, cls_loss = 0.787\nstep 37/41, cls_loss = 0.912\nstep 38/41, cls_loss = 0.747\nstep 39/41, cls_loss = 0.764\nstep 40/41, cls_loss = 0.741\nstep 0/41, cls_loss = 0.761\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:10<00:00,  2.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.647\nstep 1/41, cls_loss = 0.847\nstep 2/41, cls_loss = 0.827\nstep 3/41, cls_loss = 0.711\nstep 4/41, cls_loss = 0.707\nstep 5/41, cls_loss = 0.774\nstep 6/41, cls_loss = 0.780\nstep 7/41, cls_loss = 0.795\nstep 8/41, cls_loss = 0.656\nstep 9/41, cls_loss = 0.695\nstep 10/41, cls_loss = 0.709\nstep 11/41, cls_loss = 0.749\nstep 12/41, cls_loss = 0.994\nstep 13/41, cls_loss = 1.008\nstep 14/41, cls_loss = 0.866\nstep 15/41, cls_loss = 0.814\nstep 16/41, cls_loss = 0.650\nstep 17/41, cls_loss = 0.851\nstep 18/41, cls_loss = 0.856\nstep 19/41, cls_loss = 0.767\nstep 20/41, cls_loss = 0.721\nstep 21/41, cls_loss = 0.723\nstep 22/41, cls_loss = 0.724\nstep 23/41, cls_loss = 0.724\nstep 24/41, cls_loss = 0.830\nstep 25/41, cls_loss = 0.739\nstep 26/41, cls_loss = 0.759\nstep 27/41, cls_loss = 0.764\nstep 28/41, cls_loss = 0.788\nstep 29/41, cls_loss = 0.743\nstep 30/41, cls_loss = 0.745\nstep 31/41, cls_loss = 0.761\nstep 32/41, cls_loss = 0.858\nstep 33/41, cls_loss = 0.844\nstep 34/41, cls_loss = 0.819\nstep 35/41, cls_loss = 0.796\nstep 36/41, cls_loss = 0.733\nstep 37/41, cls_loss = 0.777\nstep 38/41, cls_loss = 0.728\nstep 39/41, cls_loss = 0.707\nstep 40/41, cls_loss = 0.856\nstep 0/41, cls_loss = 0.772\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:09<00:00,  1.98s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.656\nstep 1/41, cls_loss = 0.687\nstep 2/41, cls_loss = 0.750\nstep 3/41, cls_loss = 0.769\nstep 4/41, cls_loss = 0.674\nstep 5/41, cls_loss = 0.685\nstep 6/41, cls_loss = 0.723\nstep 7/41, cls_loss = 0.752\nstep 8/41, cls_loss = 0.772\nstep 9/41, cls_loss = 0.787\nstep 10/41, cls_loss = 0.718\nstep 11/41, cls_loss = 0.681\nstep 12/41, cls_loss = 0.724\nstep 13/41, cls_loss = 0.697\nstep 14/41, cls_loss = 0.755\nstep 15/41, cls_loss = 0.798\nstep 16/41, cls_loss = 0.654\nstep 17/41, cls_loss = 0.773\nstep 18/41, cls_loss = 0.718\nstep 19/41, cls_loss = 0.745\nstep 20/41, cls_loss = 0.734\nstep 21/41, cls_loss = 0.737\nstep 22/41, cls_loss = 0.673\nstep 23/41, cls_loss = 0.749\nstep 24/41, cls_loss = 0.712\nstep 25/41, cls_loss = 0.731\nstep 26/41, cls_loss = 0.785\nstep 27/41, cls_loss = 0.723\nstep 28/41, cls_loss = 0.774\nstep 29/41, cls_loss = 0.722\nstep 30/41, cls_loss = 0.736\nstep 31/41, cls_loss = 0.706\nstep 32/41, cls_loss = 0.692\nstep 33/41, cls_loss = 0.761\nstep 34/41, cls_loss = 0.786\nstep 35/41, cls_loss = 0.814\nstep 36/41, cls_loss = 0.851\nstep 37/41, cls_loss = 0.767\nstep 38/41, cls_loss = 0.713\nstep 39/41, cls_loss = 0.786\nstep 40/41, cls_loss = 0.717\nstep 0/41, cls_loss = 0.718\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:10<00:00,  2.12s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.646\nstep 1/41, cls_loss = 0.745\nstep 2/41, cls_loss = 0.693\nstep 3/41, cls_loss = 0.774\nstep 4/41, cls_loss = 0.815\nstep 5/41, cls_loss = 0.841\nstep 6/41, cls_loss = 0.703\nstep 7/41, cls_loss = 0.812\nstep 8/41, cls_loss = 0.713\nstep 9/41, cls_loss = 0.691\nstep 10/41, cls_loss = 0.701\nstep 11/41, cls_loss = 0.715\nstep 12/41, cls_loss = 0.781\nstep 13/41, cls_loss = 0.708\nstep 14/41, cls_loss = 0.635\nstep 15/41, cls_loss = 0.714\nstep 16/41, cls_loss = 0.754\nstep 17/41, cls_loss = 0.727\nstep 18/41, cls_loss = 0.681\nstep 19/41, cls_loss = 0.692\nstep 20/41, cls_loss = 0.665\nstep 21/41, cls_loss = 0.703\nstep 22/41, cls_loss = 0.668\nstep 23/41, cls_loss = 0.699\nstep 24/41, cls_loss = 0.703\nstep 25/41, cls_loss = 0.727\nstep 26/41, cls_loss = 0.629\nstep 27/41, cls_loss = 0.752\nstep 28/41, cls_loss = 0.736\nstep 29/41, cls_loss = 0.736\nstep 30/41, cls_loss = 0.698\nstep 31/41, cls_loss = 0.697\nstep 32/41, cls_loss = 0.734\nstep 33/41, cls_loss = 0.699\nstep 34/41, cls_loss = 0.691\nstep 35/41, cls_loss = 0.734\nstep 36/41, cls_loss = 0.734\nstep 37/41, cls_loss = 0.731\nstep 38/41, cls_loss = 0.831\nstep 39/41, cls_loss = 0.853\nstep 40/41, cls_loss = 0.791\nstep 0/41, cls_loss = 0.790\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:10<00:00,  2.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.639\nstep 1/41, cls_loss = 0.709\nstep 2/41, cls_loss = 0.734\nstep 3/41, cls_loss = 0.748\nstep 4/41, cls_loss = 0.704\nstep 5/41, cls_loss = 0.685\nstep 6/41, cls_loss = 0.645\nstep 7/41, cls_loss = 0.654\nstep 8/41, cls_loss = 0.663\nstep 9/41, cls_loss = 0.706\nstep 10/41, cls_loss = 0.709\nstep 11/41, cls_loss = 0.727\nstep 12/41, cls_loss = 0.714\nstep 13/41, cls_loss = 0.739\nstep 14/41, cls_loss = 0.743\nstep 15/41, cls_loss = 0.716\nstep 16/41, cls_loss = 0.774\nstep 17/41, cls_loss = 0.733\nstep 18/41, cls_loss = 0.679\nstep 19/41, cls_loss = 0.773\nstep 20/41, cls_loss = 0.661\nstep 21/41, cls_loss = 0.742\nstep 22/41, cls_loss = 0.693\nstep 23/41, cls_loss = 0.617\nstep 24/41, cls_loss = 0.725\nstep 25/41, cls_loss = 0.730\nstep 26/41, cls_loss = 0.656\nstep 27/41, cls_loss = 0.715\nstep 28/41, cls_loss = 0.672\nstep 29/41, cls_loss = 0.712\nstep 30/41, cls_loss = 0.656\nstep 31/41, cls_loss = 0.820\nstep 32/41, cls_loss = 0.836\nstep 33/41, cls_loss = 0.775\nstep 34/41, cls_loss = 0.661\nstep 35/41, cls_loss = 0.647\nstep 36/41, cls_loss = 0.660\nstep 37/41, cls_loss = 0.740\nstep 38/41, cls_loss = 0.674\nstep 39/41, cls_loss = 0.707\nstep 40/41, cls_loss = 0.639\nstep 0/41, cls_loss = 0.647\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:10<00:00,  2.05s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.658\nstep 1/41, cls_loss = 0.655\nstep 2/41, cls_loss = 0.649\nstep 3/41, cls_loss = 0.670\nstep 4/41, cls_loss = 0.718\nstep 5/41, cls_loss = 0.723\nstep 6/41, cls_loss = 0.674\nstep 7/41, cls_loss = 0.656\nstep 8/41, cls_loss = 0.655\nstep 9/41, cls_loss = 0.733\nstep 10/41, cls_loss = 0.688\nstep 11/41, cls_loss = 0.657\nstep 12/41, cls_loss = 0.757\nstep 13/41, cls_loss = 0.760\nstep 14/41, cls_loss = 0.732\nstep 15/41, cls_loss = 0.754\nstep 16/41, cls_loss = 0.687\nstep 17/41, cls_loss = 0.638\nstep 18/41, cls_loss = 0.693\nstep 19/41, cls_loss = 0.725\nstep 20/41, cls_loss = 0.760\nstep 21/41, cls_loss = 0.650\nstep 22/41, cls_loss = 0.653\nstep 23/41, cls_loss = 0.599\nstep 24/41, cls_loss = 0.717\nstep 25/41, cls_loss = 0.719\nstep 26/41, cls_loss = 0.640\nstep 27/41, cls_loss = 0.655\nstep 28/41, cls_loss = 0.662\nstep 29/41, cls_loss = 0.653\nstep 30/41, cls_loss = 0.646\nstep 31/41, cls_loss = 0.671\nstep 32/41, cls_loss = 0.639\nstep 33/41, cls_loss = 0.703\nstep 34/41, cls_loss = 0.635\nstep 35/41, cls_loss = 0.659\nstep 36/41, cls_loss = 0.683\nstep 37/41, cls_loss = 0.621\nstep 38/41, cls_loss = 0.676\nstep 39/41, cls_loss = 0.665\nstep 40/41, cls_loss = 0.682\nstep 0/41, cls_loss = 0.757\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:11<00:00,  2.23s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.627\nstep 1/41, cls_loss = 0.759\nstep 2/41, cls_loss = 0.798\nstep 3/41, cls_loss = 0.626\nstep 4/41, cls_loss = 0.644\nstep 5/41, cls_loss = 0.627\nstep 6/41, cls_loss = 0.757\nstep 7/41, cls_loss = 0.789\nstep 8/41, cls_loss = 0.671\nstep 9/41, cls_loss = 0.661\nstep 10/41, cls_loss = 0.636\nstep 11/41, cls_loss = 0.693\nstep 12/41, cls_loss = 0.678\nstep 13/41, cls_loss = 0.624\nstep 14/41, cls_loss = 0.600\nstep 15/41, cls_loss = 0.614\nstep 16/41, cls_loss = 0.597\nstep 17/41, cls_loss = 0.690\nstep 18/41, cls_loss = 0.615\nstep 19/41, cls_loss = 0.751\nstep 20/41, cls_loss = 0.699\nstep 21/41, cls_loss = 0.661\nstep 22/41, cls_loss = 0.679\nstep 23/41, cls_loss = 0.705\nstep 24/41, cls_loss = 0.681\nstep 25/41, cls_loss = 0.651\nstep 26/41, cls_loss = 0.701\nstep 27/41, cls_loss = 0.642\nstep 28/41, cls_loss = 0.604\nstep 29/41, cls_loss = 0.704\nstep 30/41, cls_loss = 0.634\nstep 31/41, cls_loss = 0.609\nstep 32/41, cls_loss = 0.696\nstep 33/41, cls_loss = 0.636\nstep 34/41, cls_loss = 0.668\nstep 35/41, cls_loss = 0.647\nstep 36/41, cls_loss = 0.750\nstep 37/41, cls_loss = 0.734\nstep 38/41, cls_loss = 0.637\nstep 39/41, cls_loss = 0.707\nstep 40/41, cls_loss = 0.738\nstep 0/41, cls_loss = 0.643\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:10<00:00,  2.05s/it]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.659\nstep 1/41, cls_loss = 0.618\nstep 2/41, cls_loss = 0.620\nstep 3/41, cls_loss = 0.676\nstep 4/41, cls_loss = 0.641\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-b5e81cfb3fee>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-535bf636780b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2326\u001b[0m                 )\n\u001b[1;32m   2327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m     def reduce(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":6},{"cell_type":"markdown","source":"batch_size 64 epoch 20","metadata":{}},{"cell_type":"code","source":"modelz = AgeAlexNet(pretrainded=True,modelpath=\"/kaggle/working/checkpoint/epoch_20_iter_0.pth\").cuda()\nmodel=AgeClassify(modelz)\noptim=torch.optim.Adam(modelz.parameters(),lr=1e-5,betas=(0.5, 0.999))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T09:52:41.429239Z","iopub.execute_input":"2024-12-20T09:52:41.429528Z","iopub.status.idle":"2024-12-20T09:52:42.253033Z","shell.execute_reply.started":"2024-12-20T09:52:41.429506Z","shell.execute_reply":"2024-12-20T09:52:42.252368Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-7-cc13c5de9fd8>:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  pretrained_dict = torch.load(path)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from tqdm import tqdm\nimport os\n\n#define\nmax_epoches = 10\nbatch_size = 64\nsave_interval = 20000\nval_interval = 20000\n\ntrain_loader = torch.utils.data.DataLoader(\n    dataset=train_dataset,\n    batch_size=batch_size,\n    shuffle=True\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    dataset=test_dataset,\n    batch_size=batch_size,\n    shuffle=True\n)\n\nsaved_model_folder = '/kaggle/working/checkpoint2'\ncheck_dir(saved_model_folder)\n\nfor epoch in range(max_epoches):\n    for train_idx, (img,label) in enumerate(train_loader):\n        img=img.cuda()\n        label=label.cuda()\n\n        #train\n        optim.zero_grad()\n        model.train(img,label)\n        loss=model.loss\n        loss.backward()\n        optim.step()\n\n        if train_idx % 36 == 0:\n            print('step %d/%d, cls_loss = %.3f' % (train_idx, len(train_loader), loss))\n\n        # save the parameters at the end of each save interval\n        if train_idx*batch_size % save_interval == 0:\n            model.save_model(dir=saved_model_folder,\n                              filename='epoch_%d_iter_%d.pth'%(epoch, train_idx))\n            print('checkpoint has been created!')\n\n        #val step\n\n        if train_idx % val_interval == 0:\n            train_correct=0\n            train_total=0\n            with torch.no_grad():\n                for val_img,val_label in tqdm(test_loader):\n                    val_img=val_img.cuda()\n                    val_label=val_label.cuda()\n                    output=model.val(val_img)\n                    train_correct += (output == val_label).sum()\n                    train_total += val_img.size()[0]\n\n            print('validate has been finished!')\n            print('val_acc = %.3f' % (train_correct.cpu().numpy()/train_total))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T09:57:58.016085Z","iopub.execute_input":"2024-12-20T09:57:58.016441Z","iopub.status.idle":"2024-12-20T10:15:12.584817Z","shell.execute_reply.started":"2024-12-20T09:57:58.016411Z","shell.execute_reply":"2024-12-20T10:15:12.584134Z"}},"outputs":[{"name":"stdout","text":"step 0/328, cls_loss = 0.770\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 36/36 [00:09<00:00,  3.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.666\nstep 36/328, cls_loss = 0.516\nstep 72/328, cls_loss = 0.651\nstep 108/328, cls_loss = 0.480\nstep 144/328, cls_loss = 0.545\nstep 180/328, cls_loss = 0.577\nstep 216/328, cls_loss = 0.615\nstep 252/328, cls_loss = 0.469\nstep 288/328, cls_loss = 0.461\nstep 324/328, cls_loss = 0.574\nstep 0/328, cls_loss = 0.630\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 36/36 [00:09<00:00,  3.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.652\nstep 36/328, cls_loss = 0.577\nstep 72/328, cls_loss = 0.428\nstep 108/328, cls_loss = 0.707\nstep 144/328, cls_loss = 0.448\nstep 180/328, cls_loss = 0.734\nstep 216/328, cls_loss = 0.561\nstep 252/328, cls_loss = 0.511\nstep 288/328, cls_loss = 0.483\nstep 324/328, cls_loss = 0.420\nstep 0/328, cls_loss = 0.555\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 36/36 [00:10<00:00,  3.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.664\nstep 36/328, cls_loss = 0.532\nstep 72/328, cls_loss = 0.641\nstep 108/328, cls_loss = 0.750\nstep 144/328, cls_loss = 0.458\nstep 180/328, cls_loss = 0.525\nstep 216/328, cls_loss = 0.736\nstep 252/328, cls_loss = 0.501\nstep 288/328, cls_loss = 0.479\nstep 324/328, cls_loss = 0.621\nstep 0/328, cls_loss = 0.542\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 36/36 [00:09<00:00,  3.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.664\nstep 36/328, cls_loss = 0.502\nstep 72/328, cls_loss = 0.379\nstep 108/328, cls_loss = 0.419\nstep 144/328, cls_loss = 0.524\nstep 180/328, cls_loss = 0.533\nstep 216/328, cls_loss = 0.524\nstep 252/328, cls_loss = 0.485\nstep 288/328, cls_loss = 0.544\nstep 324/328, cls_loss = 0.435\nstep 0/328, cls_loss = 0.544\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 36/36 [00:09<00:00,  3.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.655\nstep 36/328, cls_loss = 0.376\nstep 72/328, cls_loss = 0.495\nstep 108/328, cls_loss = 0.485\nstep 144/328, cls_loss = 0.494\nstep 180/328, cls_loss = 0.711\nstep 216/328, cls_loss = 0.459\nstep 252/328, cls_loss = 0.646\nstep 288/328, cls_loss = 0.542\nstep 324/328, cls_loss = 0.486\nstep 0/328, cls_loss = 0.495\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 36/36 [00:09<00:00,  3.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.659\nstep 36/328, cls_loss = 0.391\nstep 72/328, cls_loss = 0.531\nstep 108/328, cls_loss = 0.514\nstep 144/328, cls_loss = 0.374\nstep 180/328, cls_loss = 0.555\nstep 216/328, cls_loss = 0.501\nstep 252/328, cls_loss = 0.480\nstep 288/328, cls_loss = 0.349\nstep 324/328, cls_loss = 0.457\nstep 0/328, cls_loss = 0.429\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 36/36 [00:10<00:00,  3.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.655\nstep 36/328, cls_loss = 0.570\nstep 72/328, cls_loss = 0.380\nstep 108/328, cls_loss = 0.311\nstep 144/328, cls_loss = 0.404\nstep 180/328, cls_loss = 0.423\nstep 216/328, cls_loss = 0.415\nstep 252/328, cls_loss = 0.472\nstep 288/328, cls_loss = 0.347\nstep 324/328, cls_loss = 0.451\nstep 0/328, cls_loss = 0.426\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 36/36 [00:09<00:00,  3.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.652\nstep 36/328, cls_loss = 0.508\nstep 72/328, cls_loss = 0.417\nstep 108/328, cls_loss = 0.358\nstep 144/328, cls_loss = 0.468\nstep 180/328, cls_loss = 0.437\nstep 216/328, cls_loss = 0.691\nstep 252/328, cls_loss = 0.333\nstep 288/328, cls_loss = 0.549\nstep 324/328, cls_loss = 0.627\nstep 0/328, cls_loss = 0.458\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 36/36 [00:09<00:00,  3.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.650\nstep 36/328, cls_loss = 0.538\nstep 72/328, cls_loss = 0.486\nstep 108/328, cls_loss = 0.503\nstep 144/328, cls_loss = 0.395\nstep 180/328, cls_loss = 0.370\nstep 216/328, cls_loss = 0.552\nstep 252/328, cls_loss = 0.513\nstep 288/328, cls_loss = 0.421\nstep 324/328, cls_loss = 0.409\nstep 0/328, cls_loss = 0.289\ncheckpoint has been created!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 36/36 [00:09<00:00,  3.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"validate has been finished!\nval_acc = 0.652\nstep 36/328, cls_loss = 0.411\nstep 72/328, cls_loss = 0.351\nstep 108/328, cls_loss = 0.360\nstep 144/328, cls_loss = 0.439\nstep 180/328, cls_loss = 0.411\nstep 216/328, cls_loss = 0.563\nstep 252/328, cls_loss = 0.474\nstep 288/328, cls_loss = 0.338\nstep 324/328, cls_loss = 0.298\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!mkdir -r /kaggle/working/model\n!cp /kaggle/working/checkpoint2/epoch_0_iter_0.pth /kaggle/working/model\n!cp /kaggle/working/checkpoint2/epoch_2_iter_0.pth /kaggle/working/model\n!cp /kaggle/working/checkpoint2/epoch_9_iter_0.pth /kaggle/working/model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T10:15:58.727759Z","iopub.execute_input":"2024-12-20T10:15:58.728081Z","iopub.status.idle":"2024-12-20T10:16:00.546025Z","shell.execute_reply.started":"2024-12-20T10:15:58.728052Z","shell.execute_reply":"2024-12-20T10:16:00.545084Z"}},"outputs":[{"name":"stdout","text":"mkdir: invalid option -- 'r'\nTry 'mkdir --help' for more information.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!zip -r model.zip /kaggle/working/model\n\nimport kagglehub\n\n# Replace with path to directory containing model files.\nLOCAL_MODEL_DIR = '/kaggle/working/model.zip'\n\nMODEL_SLUG = 'faceAlexnet_pretrain' # Replace with model slug.\n\n# Learn more about naming model variations at\n# https://www.kaggle.com/docs/models#name-model.\nVARIATION_SLUG = 'default' # Replace with variation slug.\n\nkagglehub.model_upload(\n  handle = f\"poongln/{MODEL_SLUG}/keras/{VARIATION_SLUG}\",\n  local_model_dir = LOCAL_MODEL_DIR,\n  version_notes = 'Update 2024-12-20')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T10:16:31.854680Z","iopub.execute_input":"2024-12-20T10:16:31.854977Z","iopub.status.idle":"2024-12-20T10:18:13.854346Z","shell.execute_reply.started":"2024-12-20T10:16:31.854954Z","shell.execute_reply":"2024-12-20T10:18:13.853594Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/model/ (stored 0%)\n  adding: kaggle/working/model/epoch_0_iter_0.pth (deflated 8%)\n  adding: kaggle/working/model/epoch_2_iter_0.pth (deflated 8%)\n  adding: kaggle/working/model/epoch_9_iter_0.pth (deflated 7%)\nUploading Model https://www.kaggle.com/models/poongln/faceAlexnet_pretrain/keras/default ...\nModel 'faceAlexnet_pretrain' does not exist or access is forbidden for user 'poongln'. Creating or handling Model...\nModel 'faceAlexnet_pretrain' Created.\nStarting upload for file /kaggle/working/model.zip\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 631M/631M [00:22<00:00, 28.5MB/s] ","output_type":"stream"},{"name":"stdout","text":"Upload successful: /kaggle/working/model.zip (602MB)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Your model instance has been created.\nFiles are being processed...\nSee at: https://www.kaggle.com/models/poongln/faceAlexnet_pretrain/keras/default\n","output_type":"stream"}],"execution_count":19}]}